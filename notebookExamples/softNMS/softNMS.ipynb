{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center; font-style: strong;\">Soft-NMS</p>\n",
    "### <p style=\"text-align: center;\">(Almond: 0.8.0, Scala: 2.12.8)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"darwin-cpu-x86_64\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.tensorflow.framework.GraphDef\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.{ Files, Image => TImage }\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.client.{ FeedMap, Session }\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.{ Graph, Shape, NewAxis }\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.{ UByte, tf, Tensor, --- }\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{BufferedInputStream, File, FileInputStream}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ListBuffer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.math.{min, max, exp, sqrt, abs}\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.tensorflow.framework.GraphDef\n",
    "import org.platanios.tensorflow.api.ops.{ Files, Image => TImage }\n",
    "import org.platanios.tensorflow.api.core.client.{ FeedMap, Session }\n",
    "import org.platanios.tensorflow.api.core.{ Graph, Shape, NewAxis }\n",
    "import org.platanios.tensorflow.api.{ UByte, tf, Tensor, --- }\n",
    "import java.io.{BufferedInputStream, File, FileInputStream}\n",
    "import scala.io.Source\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import scala.math.{min, max, exp, sqrt, abs}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "Just modify *modelsFileName* and *imageName* and after respect the following project structure :\n",
    "\n",
    "```\n",
    "data    \n",
    "└───labelsMap\n",
    "   │   X.txt\n",
    "   │   Y.txt\n",
    "└───models\n",
    "   │   X.pb\n",
    "   │   Y.pb   \n",
    "images\n",
    "│   Z.txt\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbasedir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"data\"\u001b[39m\n",
       "\u001b[36mimageName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"0049.png\"\u001b[39m\n",
       "\u001b[36mmodelsFileName\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\u001b[32m\"coco\"\u001b[39m, \u001b[32m\"kitti\"\u001b[39m)\n",
       "\u001b[36mimageFilePath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"/Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/images/0049.png\"\u001b[39m\n",
       "\u001b[36mlabelsMapPath\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"/Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/data/labelsMap/coco.txt\"\u001b[39m,\n",
       "  \u001b[32m\"/Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/data/labelsMap/kitti.txt\"\u001b[39m\n",
       ")\n",
       "\u001b[36mmodelsGraphPath\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[32m\"/Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/data/models/coco.pb\"\u001b[39m,\n",
       "  \u001b[32m\"/Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/data/models/kitti.pb\"\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val basedir = \"data\"\n",
    "val imageName = \"0049.png\"\n",
    "val modelsFileName = List(\"coco\", \"kitti\")\n",
    "val imageFilePath = s\"${System.getProperty(\"user.dir\")}/images/${imageName}\"\n",
    "\n",
    "val labelsMapPath = modelsFileName.map(name => s\"${System.getProperty(\"user.dir\")}/${basedir}/labelsMap/${name}.txt\")\n",
    "val modelsGraphPath = modelsFileName.map(name => s\"${System.getProperty(\"user.dir\")}/${basedir}/models/${name}.pb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"jp-RenderedText\">\n",
       "<pre><code><span style=\"color: rgb(0, 187, 187)\"><span class=\"ansi-cyan-fg\">graphs</span></span>: <span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">List</span></span>[<span style=\"color: rgb(0, 187, 0)\"><span class=\"ansi-green-fg\">Graph</span></span>] = <style>@keyframes fadein { from { opacity: 0; } to { opacity: 1; } }</style><span style=\"animation: fadein 2s;\"><span style=\"color: yellow\"><span class=\"ansi-yellow-fg\">List</span></span>(\n",
       "  org.platanios.tensorflow.api.core.Graph@8801e553,\n",
       "  org.platanios.tensorflow.api.core.Graph@8872f113\n",
       ")</span></code></pre>\n",
       "</div>"
      ],
      "text/plain": [
       "\u001b[36mgraphs\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mGraph\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  org.platanios.tensorflow.api.core.Graph@8801e553,\n",
       "  org.platanios.tensorflow.api.core.Graph@8872f113\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lazy val graphs = modelsGraphPath.map(model => Graph.fromGraphDef(GraphDef.parseFrom(new BufferedInputStream(new FileInputStream(new File(model))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msessions\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mSession\u001b[39m] = \u001b[33mList\u001b[39m(\n",
       "  org.platanios.tensorflow.api.core.client.Session@4a3b7dad,\n",
       "  org.platanios.tensorflow.api.core.client.Session@329aceec\n",
       ")\n",
       "\u001b[36msessionSimple\u001b[39m: \u001b[32mSession\u001b[39m = org.platanios.tensorflow.api.core.client.Session@23dd192f"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sessions = graphs.map(Session(_))\n",
    "val sessionSimple = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare recuperation of graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mplaceholdersOutput\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mops\u001b[39m.\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]]] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m\"detectionBoxes\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_boxes, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"detectionScores\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_scores, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"detectionClasses\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_classes, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"numDetections\"\u001b[39m -> \u001b[33mOutput\u001b[39m(num_detections, \u001b[32m0\u001b[39m)\n",
       "  ),\n",
       "  \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m\"detectionBoxes\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_boxes, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"detectionScores\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_scores, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"detectionClasses\"\u001b[39m -> \u001b[33mOutput\u001b[39m(detection_classes, \u001b[32m0\u001b[39m),\n",
       "    \u001b[32m\"numDetections\"\u001b[39m -> \u001b[33mOutput\u001b[39m(num_detections, \u001b[32m0\u001b[39m)\n",
       "  )\n",
       ")\n",
       "\u001b[36mplaceholdersImage\u001b[39m: \u001b[32mList\u001b[39m[\u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mops\u001b[39m.\u001b[32mOutput\u001b[39m[\u001b[32mUByte\u001b[39m]] = \u001b[33mList\u001b[39m(\n",
       "  \u001b[33mOutput\u001b[39m(image_tensor, \u001b[32m0\u001b[39m),\n",
       "  \u001b[33mOutput\u001b[39m(image_tensor, \u001b[32m0\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val placeholdersOutput = graphs.map { graph => \n",
    "    Map(\"detectionBoxes\" -> graph.getOutputByName(\"detection_boxes:0\").toFloat,\n",
    "        \"detectionScores\" -> graph.getOutputByName(\"detection_scores:0\").toFloat,\n",
    "        \"detectionClasses\" -> graph.getOutputByName(\"detection_classes:0\").toFloat,\n",
    "        \"numDetections\" -> graph.getOutputByName(\"num_detections:0\").toFloat)\n",
    "}\n",
    "\n",
    "val placeholdersImage = graphs.map(_.getOutputByName(\"image_tensor:0\").toUByte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and transform image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mimgTensor\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mops\u001b[39m.\u001b[32mOutput\u001b[39m[\u001b[32mUByte\u001b[39m] = \u001b[33mOutput\u001b[39m(DecodePng, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mfileNamePlaceholder\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mapi\u001b[39m.\u001b[32mops\u001b[39m.\u001b[32mOutput\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mOutput\u001b[39m(\n",
       "  Placeholder,\n",
       "  \u001b[32m0\u001b[39m\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (imgTensor, fileNamePlaceholder) = tf.createWith() {\n",
    "    val fileNamePlaceholder = tf.placeholder[String]()\n",
    "    val fileTensor = Files.readFile(fileNamePlaceholder)\n",
    "    val imgTensor = TImage.decodePng(fileTensor, 3)\n",
    "    (imgTensor, fileNamePlaceholder)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31morg.platanios.tensorflow.jni.NotFoundException: /Users/vincentbrule/Desktop/notebook_project/notebookExamples/softNMS/images/0049.png; No such file or directory\n\t [[{{node ReadFile}}]]\u001b[39m\n  org.platanios.tensorflow.jni.Session$.run(\u001b[32mNative Method\u001b[39m)\n  org.platanios.tensorflow.api.core.client.Session.runHelper(\u001b[32mSession.scala\u001b[39m:\u001b[32m165\u001b[39m)\n  org.platanios.tensorflow.api.core.client.Session.run(\u001b[32mSession.scala\u001b[39m:\u001b[32m83\u001b[39m)\n  ammonite.$sess.cmd7$Helper.$anonfun$imageOuts$1(\u001b[32mcmd7.sc\u001b[39m:\u001b[32m5\u001b[39m)\n  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m62\u001b[39m)\n  org.platanios.tensorflow.api.ops.Op$.createWith(\u001b[32mOp.scala\u001b[39m:\u001b[32m2043\u001b[39m)\n  org.platanios.tensorflow.api.ops.package$API.createWith(\u001b[32mpackage.scala\u001b[39m:\u001b[32m120\u001b[39m)\n  org.platanios.tensorflow.api.ops.package$API.createWith$(\u001b[32mpackage.scala\u001b[39m:\u001b[32m114\u001b[39m)\n  org.platanios.tensorflow.api.package$tf$.createWith(\u001b[32mpackage.scala\u001b[39m:\u001b[32m294\u001b[39m)\n  ammonite.$sess.cmd7$Helper.<init>(\u001b[32mcmd7.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd7$.<init>(\u001b[32mcmd7.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd7$.<clinit>(\u001b[32mcmd7.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val imageOuts = tf.createWith() {\n",
    "    val file = new File(imageFilePath)\n",
    "    val fileNameTensor = Tensor.fill(Shape())(file.getAbsolutePath())\n",
    "    val feedImg = FeedMap(Map(fileNamePlaceholder -> fileNameTensor))\n",
    "    sessionSimple.run(fetches = imgTensor, feeds = feedImg)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val listFeeds = placeholdersImage.map(placeholder => FeedMap(Map(placeholder -> imageOuts.slice(NewAxis, ---))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read labelsMap file and transform it into Scala Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val labelsMapToString = labelsMapPath.map { path => \n",
    "    Source.fromFile(path).getLines.map { line =>\n",
    "        val splitLine = line.split(\" \")\n",
    "        splitLine(0).toInt -> splitLine(1)\n",
    "    }.toMap\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val threshold = 0.5 // Thereshold to discard detection below that\n",
    "val height = imageOuts.shape(0)\n",
    "val width = imageOuts.shape(1)\n",
    "val sigma = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*boxes* = Positions of object detected\n",
    "\n",
    "*score* = Confidence for each detection\n",
    "\n",
    "*classes* = number corresponding to a class inside our labelMap previously defined\n",
    "\n",
    "*num* = Number of detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val detections = sessions.zipWithIndex.map { case (s, index) =>\n",
    "      s.run(\n",
    "        fetches =\n",
    "          Seq(placeholdersOutput(index)(\"detectionBoxes\"), placeholdersOutput(index)(\"detectionScores\"), placeholdersOutput(index)(\"detectionClasses\"), placeholdersOutput(index)(\"numDetections\")),\n",
    "          feeds = listFeeds(index))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxes filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Use relative positions to be able to draw bounding box after\n",
    "val listTabBoxes = detections.zipWithIndex.map { case (detection, index) => \n",
    "    for {\n",
    "        i <- 0 until detection(3).scalar.toInt\n",
    "        labelId = detection(2)(0, i).toFloat.scalar.toInt\n",
    "        box = detection(0)(0, i).toFloat.entriesIterator.toSeq\n",
    "        y1 = (box(0))\n",
    "        x1 = (box(1))\n",
    "        y2 = (box(2))\n",
    "        x2 = (box(3))\n",
    "        labelBox = List(y1, x1, y2, x2)\n",
    "        score = detection(1)(0, i).toFloat.scalar\n",
    "  } yield (labelsMapToString(index)(labelId), score, labelBox)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scala boxes to Tensorflow boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// We start by keep only positions and flatMap all boxes and transform it into Tensor\n",
    "val listFlatBoxes = listTabBoxes.map { tabBoxesFiltered => Tensor(tabBoxesFiltered.flatMap{ case(_, _, positions) => positions }) }\n",
    "// We reshape it to have shape like : [batch, num_bounding_boxes, 4]\n",
    "val listTensorWithAllBoxes = listFlatBoxes.map { tensorFlatBoxes => tf.reshape(tensorFlatBoxes, Shape(1, tensorFlatBoxes.shape(1) / 4, 4)) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// We combined detections boxes from all models\n",
    "val boxesCombined = Tensor(listTabBoxes.flatMap {boxes => boxes.flatMap { case(_, _, positions) => positions } })\n",
    "// We obtain a Tensor with Shape [1, num_all_boxes, 4]\n",
    "val tensorBoxesCombined = tf.reshape(boxesCombined, Shape(1, listTabBoxes.foldLeft(0) { (acc, i) => acc + i.length }, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// list with image + detection boxes for each model\n",
    "val listImageToDisplay = listTensorWithAllBoxes.map { tensorWithAllBoxes =>\n",
    "    tf.reshape(TImage.drawBoundingBoxes(imageOuts.slice(NewAxis, ---).toFloat, tensorWithAllBoxes).toUByte, Shape(height, width, 3))\n",
    "}\n",
    "\n",
    "// image with all boxes\n",
    "val imageCombinedToDisplay = tf.reshape(TImage.drawBoundingBoxes(imageOuts.slice(NewAxis, ---).toFloat, tensorBoxesCombined).toUByte, Shape(height, width, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val listImgFinal = listImageToDisplay.map { image => \n",
    "    tf.createWith() {\n",
    "        val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(image))\n",
    "        sessionSimple.run(fetches = exampleImage)\n",
    "    }\n",
    "}\n",
    "\n",
    "val imgFinalCombined = tf.createWith() {\n",
    "    val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(imageCombinedToDisplay))\n",
    "    sessionSimple.run(fetches = exampleImage)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listImgFinal.foreach { image => Image(image.entriesIterator.toArray).withFormat(Image.PNG).withWidth(500).display }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(imgFinalCombined.entriesIterator.toArray).withFormat(Image.PNG).withWidth(500).display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft-NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Group identification by class because Soft-NMS works for each class separately\n",
    "val mapDetections = listTabBoxes.flatten.map { case(s, c, l) => (s, c, List(l(0)*height, l(1)*width, l(2)*height, l(3)*width)) }.groupBy { case(c, _, _) => c }\n",
    "// Keep only car and person detections\n",
    "var listBoxesCar = mapDetections(\"car\").to[ListBuffer]\n",
    "var listBoxesPerson = mapDetections(\"person\").to[ListBuffer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation transformed into more functional way\n",
    "Below this, you can find the python copied implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softNMS(boxesWithScore: ListBuffer[(String, Float, List[Float])]): List[List[Float]] = {\n",
    "    var listInitial = boxesWithScore.clone()\n",
    "    var listFinalDetectionBoxes = ListBuffer[List[Float]]()\n",
    "    \n",
    "    while (listInitial.nonEmpty) {\n",
    "        // Find box with the max score detection\n",
    "        val maxBox = listInitial.maxBy(_._2)\n",
    "        val List(ty1, tx1, ty2, tx2) = maxBox._3\n",
    "        listFinalDetectionBoxes += listInitial.remove(listInitial.indexOf(maxBox))._3\n",
    "        // Modify score in function of the shared area\n",
    "        listInitial = listInitial.map {\n",
    "            case (c, s, p) => \n",
    "                val area = (p(3) - p(1) + 1) * (p(2) - p(0) + 1)\n",
    "                val iw = (min(tx2, p(3)) - max(tx1, p(1)) + 1)\n",
    "                val ih = (min(ty2, p(2)) - max(ty1, p(0)) + 1)\n",
    "                val scoreWeighted = \n",
    "                    if (iw > 0 && ih > 0) {\n",
    "                        val ua = ((tx2 - tx1 + 1) * (ty2 - ty1 + 1) + area - iw * ih)\n",
    "                        val ov = iw * ih / ua\n",
    "                        s * exp(-(ov * ov) / sigma).toFloat\n",
    "                    }\n",
    "                    else s\n",
    "                (c, scoreWeighted, p)\n",
    "        }\n",
    "        // Remove boxes in function of our threshold and their nms score\n",
    "        listInitial = listInitial.filterNot(_._2 < threshold)\n",
    "    }\n",
    "    \n",
    "    listFinalDetectionBoxes.toList\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation copied from Python Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val nmsBoxes = softNMS(listBoxesCar).flatMap { case(List(y1,x1,y2,x2)) => List(y1/height, x1/width, y2/height, x2/width)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tensorNmsBoxes = Tensor(nmsBoxes)\n",
    "val tensorReshapeNmsBoxes = tf.reshape(tensorNmsBoxes, Shape(1, nmsBoxes.length / 4, 4))\n",
    "val imageCombinedNms = tf.reshape(TImage.drawBoundingBoxes(imageOuts.slice(NewAxis, ---).toFloat, tensorReshapeNmsBoxes).toUByte, Shape(height, width, 3))\n",
    "val imgFinalCombinedNms = tf.createWith() {\n",
    "    val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(imageCombinedNms))\n",
    "    sessionSimple.run(fetches = exampleImage)\n",
    "}\n",
    "Image(imgFinalCombinedNms.entriesIterator.toArray).withFormat(Image.PNG).withWidth(500).display\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
