{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2.2 : MNIST with Multiple Layer Perceptron (MLP)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(coursier.Organization(\"org.platanios\"), coursier.ModuleName(\"tensorflow_2.12\")),\n",
    "    version = \"0.4.1\",\n",
    "    // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "    attributes = coursier.Attributes(coursier.Type(\"\"), coursier.Classifier(\"darwin-cpu-x86_64\"))\n",
    "  )\n",
    ")\n",
    "\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
    "import java.nio.file.{ Files => JFiles, Paths, Path }\n",
    "\n",
    "import java.awt.{Image => JImage}\n",
    "import java.io.{BufferedInputStream, File, FileInputStream, ByteArrayOutputStream, IOException}\n",
    "import scala.io.Source\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import java.awt.image.BufferedImage\n",
    "import java.awt.Color\n",
    "import java.awt.image.BufferedImage\n",
    "import javax.imageio.ImageIO\n",
    "import scala.util.Random\n",
    "import java.util.Base64\n",
    "import java.io.PrintWriter\n",
    "import scala.io.Source\n",
    "import java.io.ByteArrayInputStream\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.client.{Session, FeedMap}\n",
    "import org.platanios.tensorflow.api.core.types.DataType\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import java.nio.file.{Files, Paths}\n",
    "import org.platanios.tensorflow.api.core.{Shape, types}\n",
    "import scala.language.postfixOps\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
    "import org.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
    "import org.platanios.tensorflow.api.ops.Output\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.learn.layers.{Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, ScalarSummary}\n",
    "import org.platanios.tensorflow.api.learn.{Model, StopCriteria, Configuration}\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.api.learn.hooks.{SummarySaver, StepHookTrigger, CheckpointSaver}\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "import java.util.Base64\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
    "import org.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
    "import org.platanios.tensorflow.api.ops.Output\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import java.nio.file.Paths\n",
    "\n",
    "\n",
    "val dataSet = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataSet.trainImages).map(_.toFloat)\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataSet.trainLabels).map(_.toLong)\n",
    "val testImages = tf.data.datasetFromTensorSlices(dataSet.testImages).map(_.toFloat)\n",
    "val testLabels = tf.data.datasetFromTensorSlices(dataSet.testLabels).map(_.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)\n",
    "val evalTrainData = trainImages.zip(trainLabels).batch(1000).prefetch(10)\n",
    "val evalTestData = testImages.zip(testLabels).batch(1000).prefetch(10)\n",
    "\n",
    "\n",
    "val input = tf.learn.Input(FLOAT32, Shape(-1, dataSet.trainImages.shape(1), dataSet.trainImages.shape(2)))\n",
    "val trainInput = tf.learn.Input(INT64, Shape(-1))\n",
    "val layer = tf.learn.Flatten[Float](\"Input/Flatten\") >>\n",
    "    tf.learn.Linear[Float](\"Layer_0/Linear\", 128) >> tf.learn.ReLU[Float](\"Layer_0/ReLU\", 0.1f) >>\n",
    "    tf.learn.Linear[Float](\"Layer_1/Linear\", 64) >> tf.learn.ReLU[Float](\"Layer_1/ReLU\", 0.1f) >>\n",
    "    tf.learn.Linear[Float](\"Layer_2/Linear\", 32) >> tf.learn.ReLU[Float](\"Layer_2/ReLU\", 0.1f) >>\n",
    "    tf.learn.Linear[Float](\"OutputLayer/Linear\", 10)\n",
    "val loss = tf.learn.SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss/CrossEntropy\") >>\n",
    "    tf.learn.Mean[Float](\"Loss/Mean\") >>\n",
    "    tf.learn.ScalarSummary[Float](\"Loss/Summary\", \"Loss\")\n",
    "val optimizer = tf.train.YellowFin()\n",
    "\n",
    "val model = tf.learn.Model.simpleSupervised(\n",
    "  input = input,\n",
    "  trainInput = trainInput,\n",
    "  layer = layer,\n",
    "  loss = loss,\n",
    "  optimizer = optimizer,\n",
    "  clipGradients = ClipGradientsByGlobalNorm(5.0f))\n",
    "\n",
    "val summariesDir = Paths.get(\"../resources/save\")\n",
    "val accMetric = tf.metrics.MapMetric(\n",
    "  (v: (Output[Float], (Output[Float], Output[Int]))) => {\n",
    "    (tf.argmax(v._1, -1, INT64).toFloat, v._2._2.toFloat)\n",
    "  }, tf.metrics.Accuracy(\"Accuracy\"))\n",
    "val estimator = tf.learn.InMemoryEstimator(\n",
    "  model,\n",
    "  tf.learn.Configuration(Some(summariesDir)),\n",
    "  tf.learn.StopCriteria(maxSteps = Some(100000)),\n",
    "  Set(\n",
    "    tf.learn.LossLogger(trigger = tf.learn.StepHookTrigger(100)),\n",
    "    tf.learn.Evaluator(\n",
    "      log = true, datasets = Seq((\"Train\", () => evalTrainData), (\"Test\", () => evalTestData)),\n",
    "      metrics = Seq(accMetric), trigger = tf.learn.StepHookTrigger(1000), name = \"Evaluator\"),\n",
    "    tf.learn.StepRateLogger(log = false, summaryDir = summariesDir, trigger = tf.learn.StepHookTrigger(100)),\n",
    "    tf.learn.SummarySaver(summariesDir, tf.learn.StepHookTrigger(100)),\n",
    "    tf.learn.CheckpointSaver(summariesDir, tf.learn.StepHookTrigger(1000))),\n",
    "  tensorBoardConfig = tf.learn.TensorBoardConfig(summariesDir, reloadInterval = 1))\n",
    "estimator.train(() => trainData, tf.learn.StopCriteria(maxSteps = Some(10000)))\n",
    "\n",
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "  val predictions = estimator.infer(() => images.toFloat)\n",
    "  predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "println(s\"Train accuracy = ${accuracy(dataSet.trainImages, dataSet.trainLabels)}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataSet.testImages, dataSet.testLabels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformImagesForPrediction(imagefilePath: String, numChannel: Int, s: Session = Session()): Tensor[UByte] = {\n",
    "    val tensorImageOuts = TImage.decodePng(Files.readFile(imagefilePath), numChannel)\n",
    "    s.run(fetches = tf.reshape(tensorImageOuts, Shape(1,28,28)))\n",
    "}\n",
    "\n",
    "def runPrediction(imagePath: String): String = {\n",
    "    val imageTest = transformImagesForPrediction(imagePath, 1)\n",
    "    val imageToDisplay = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(tf.reshape(imageTest, Shape(28, 28, 1)))))\n",
    "    Image(imageToDisplay.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    val predictions = estimator.infer(() => imageTest.toFloat)\n",
    "    s\"Le chiffre est : ${predictions.argmax(1).toInt.scalar}\"\n",
    "}\n",
    "\n",
    "runPrediction(\"../resources/images/de677a85-be92-4f72-8a9a-f97d18be26e5.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawOwnNumber(id: String) {\n",
    "    val htmlCode = JFiles.readString(Paths.get(\"../resources/drawing.html\"))\n",
    "    kernel.publish.display(almond.interpreter.api.DisplayData(Map(\"text/html\" -> htmlCode.replace(\"nameCommandToChange\", id))))\n",
    "}\n",
    "val id = java.util.UUID.randomUUID().toString // random ID use to synchronize communication between JS code and Scala code\n",
    "drawOwnNumber(id)\n",
    "kernel.publish.html(\"\", id)\n",
    "kernel.comm.receiver(id) { data =>\n",
    "    kernel.publish.updateHtml(\"Waiting\", id)\n",
    "    val nameImage = java.util.UUID.randomUUID().toString\n",
    "    val base64 = data.drop(34).dropRight(2)\n",
    "    val bis = new ByteArrayInputStream(Base64.getDecoder().decode(base64))\n",
    "    val bImage2 = ImageIO.read(bis)\n",
    "    val tmp = bImage2.getScaledInstance(28, 28, JImage.SCALE_SMOOTH)\n",
    "    val dimg = new BufferedImage(28, 28, BufferedImage.TYPE_INT_ARGB)\n",
    "    val g2d = dimg.createGraphics()\n",
    "    g2d.drawImage(tmp, 0, 0, null)\n",
    "    g2d.dispose()\n",
    "    ImageIO.write(dimg, \"png\", new File(s\"../resources/images/$nameImage.png\") )\n",
    "    val result = runPrediction(s\"../resources/images/$nameImage.png\")\n",
    "    kernel.publish.updateHtml(s\"$result\", id)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
