{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2 : MNIST with Multiple Layer Perceptron (MLP)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(coursier.Organization(\"org.platanios\"), coursier.ModuleName(\"tensorflow_2.12\")),\n",
    "    version = \"0.4.1\",\n",
    "    // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "    attributes = coursier.Attributes(coursier.Type(\"\"), coursier.Classifier(\"darwin-cpu-x86_64\"))\n",
    "  )\n",
    ")\n",
    "\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{ Files => JFiles, Paths, Path }\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.{Image => JImage}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{BufferedInputStream, File, FileInputStream, ByteArrayOutputStream, IOException}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ListBuffer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.image.BufferedImage\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.Color\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.image.BufferedImage\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjavax.imageio.ImageIO\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Base64\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.PrintWriter\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.ByteArrayInputStream\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.tf\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.tensors.Tensor\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.Shape\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.client.{Session, FeedMap}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.types.DataType\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.{Shape, types}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.language.postfixOps\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.types.UByte\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.Output\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.layers.{Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, ScalarSummary}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.{Model, StopCriteria, Configuration}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.hooks.{SummarySaver, StepHookTrigger, CheckpointSaver}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.config.TensorBoardConfig\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Base64\n",
       "\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
    "import java.nio.file.{ Files => JFiles, Paths, Path }\n",
    "\n",
    "import java.awt.{Image => JImage}\n",
    "import java.io.{BufferedInputStream, File, FileInputStream, ByteArrayOutputStream, IOException}\n",
    "import scala.io.Source\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import java.awt.image.BufferedImage\n",
    "import java.awt.Color\n",
    "import java.awt.image.BufferedImage\n",
    "import javax.imageio.ImageIO\n",
    "import scala.util.Random\n",
    "import java.util.Base64\n",
    "import java.io.PrintWriter\n",
    "import scala.io.Source\n",
    "import java.io.ByteArrayInputStream\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.client.{Session, FeedMap}\n",
    "import org.platanios.tensorflow.api.core.types.DataType\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import java.nio.file.{Files, Paths}\n",
    "import org.platanios.tensorflow.api.core.{Shape, types}\n",
    "import scala.language.postfixOps\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
    "import org.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
    "import org.platanios.tensorflow.api.ops.Output\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.learn.layers.{Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, ScalarSummary}\n",
    "import org.platanios.tensorflow.api.learn.{Model, StopCriteria, Configuration}\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.api.learn.hooks.{SummarySaver, StepHookTrigger, CheckpointSaver}\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "import java.util.Base64\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displayNumberMNIST(nb: Int) {\n",
    "    val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "    val images = dataset.trainImages\n",
    "    val imagesToDisplay = images.slice(0 :: nb, ::, ::)\n",
    "    for (index <- 0 until nb) {\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imagesToDisplay(index).reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "displayNumberMNIST(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-24 10:12:14.114 [scala-interpreter-1] INFO  MNIST Data Loader - Downloading file 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'.\n",
      "2019-07-24 10:12:24.511 [scala-interpreter-1] INFO  MNIST Data Loader - [====      ] 4838315 / 9912422 bytes downloaded.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Interrupted!\n  java.net.SocketInputStream.socketRead0(\u001b[32mNative Method\u001b[39m)\n  java.net.SocketInputStream.socketRead(\u001b[32mSocketInputStream.java\u001b[39m:\u001b[32m115\u001b[39m)\n  java.net.SocketInputStream.read(\u001b[32mSocketInputStream.java\u001b[39m:\u001b[32m168\u001b[39m)\n  java.net.SocketInputStream.read(\u001b[32mSocketInputStream.java\u001b[39m:\u001b[32m140\u001b[39m)\n  java.io.BufferedInputStream.read1(\u001b[32mBufferedInputStream.java\u001b[39m:\u001b[32m290\u001b[39m)\n  java.io.BufferedInputStream.read(\u001b[32mBufferedInputStream.java\u001b[39m:\u001b[32m351\u001b[39m)\n  sun.net.www.MeteredStream.read(\u001b[32mMeteredStream.java\u001b[39m:\u001b[32m134\u001b[39m)\n  java.io.FilterInputStream.read(\u001b[32mFilterInputStream.java\u001b[39m:\u001b[32m133\u001b[39m)\n  sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(\u001b[32mHttpURLConnection.java\u001b[39m:\u001b[32m3495\u001b[39m)\n  sun.net.www.protocol.http.HttpURLConnection$HttpInputStream.read(\u001b[32mHttpURLConnection.java\u001b[39m:\u001b[32m3488\u001b[39m)\n  org.platanios.tensorflow.data.Loader.$anonfun$download$1(\u001b[32mLoader.scala\u001b[39m:\u001b[32m73\u001b[39m)\n  org.platanios.tensorflow.data.Loader$$Lambda$2704/0x0000000800d6ec40.apply$mcI$sp(\u001b[32mUnknown Source\u001b[39m)\n  scala.runtime.java8.JFunction0$mcI$sp.apply(\u001b[32mJFunction0$mcI$sp.java\u001b[39m:\u001b[32m23\u001b[39m)\n  scala.collection.immutable.Stream$.$anonfun$continually$1(\u001b[32mStream.scala\u001b[39m:\u001b[32m1238\u001b[39m)\n  scala.collection.immutable.Stream$$$Lambda$913/0x00000008005dd840.apply(\u001b[32mUnknown Source\u001b[39m)\n  scala.collection.immutable.Stream$Cons.tail(\u001b[32mStream.scala\u001b[39m:\u001b[32m1171\u001b[39m)\n  scala.collection.immutable.Stream$Cons.tail(\u001b[32mStream.scala\u001b[39m:\u001b[32m1161\u001b[39m)\n  scala.collection.immutable.Stream.$anonfun$takeWhile$1(\u001b[32mStream.scala\u001b[39m:\u001b[32m880\u001b[39m)\n  scala.collection.immutable.Stream$$Lambda$912/0x00000008005dcc40.apply(\u001b[32mUnknown Source\u001b[39m)\n  scala.collection.immutable.Stream$Cons.tail(\u001b[32mStream.scala\u001b[39m:\u001b[32m1171\u001b[39m)\n  scala.collection.immutable.Stream$Cons.tail(\u001b[32mStream.scala\u001b[39m:\u001b[32m1161\u001b[39m)\n  scala.collection.immutable.Stream.foreach(\u001b[32mStream.scala\u001b[39m:\u001b[32m534\u001b[39m)\n  org.platanios.tensorflow.data.Loader.download(\u001b[32mLoader.scala\u001b[39m:\u001b[32m73\u001b[39m)\n  org.platanios.tensorflow.data.Loader.download$(\u001b[32mLoader.scala\u001b[39m:\u001b[32m65\u001b[39m)\n  org.platanios.tensorflow.data.image.MNISTLoader$.download(\u001b[32mMNISTLoader.scala\u001b[39m:\u001b[32m34\u001b[39m)\n  org.platanios.tensorflow.data.Loader.maybeDownload(\u001b[32mLoader.scala\u001b[39m:\u001b[32m44\u001b[39m)\n  org.platanios.tensorflow.data.Loader.maybeDownload$(\u001b[32mLoader.scala\u001b[39m:\u001b[32m37\u001b[39m)\n  org.platanios.tensorflow.data.image.MNISTLoader$.maybeDownload(\u001b[32mMNISTLoader.scala\u001b[39m:\u001b[32m34\u001b[39m)\n  org.platanios.tensorflow.data.image.MNISTLoader$.load(\u001b[32mMNISTLoader.scala\u001b[39m:\u001b[32m71\u001b[39m)\n  ammonite.$sess.cmd2$Helper.<init>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m1\u001b[39m)\n  ammonite.$sess.cmd2$.<init>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m7\u001b[39m)\n  ammonite.$sess.cmd2$.<clinit>(\u001b[32mcmd2.sc\u001b[39m:\u001b[32m-1\u001b[39m)"
     ]
    }
   ],
   "source": [
    "val dataSet = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataSet.trainImages).map(_.toFloat)\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataSet.trainLabels).map(_.toLong)\n",
    "val testImages = tf.data.datasetFromTensorSlices(dataSet.testImages).map(_.toFloat)\n",
    "val testLabels = tf.data.datasetFromTensorSlices(dataSet.testLabels).map(_.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(512)\n",
    "      .prefetch(10)\n",
    "val evalTrainData = trainImages.zip(trainLabels).batch(1000).prefetch(10)\n",
    "val evalTestData = testImages.zip(testLabels).batch(1000).prefetch(10)\n",
    "\n",
    "val input = tf.learn.Input(FLOAT32, Shape(-1, dataSet.trainImages.shape(1), dataSet.trainImages.shape(2))) //28*28\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >>\n",
    "    Linear[Float](\"Layer_0/Linear\", 128) >> ReLU[Float](\"Layer_0/Activation\", 0.001f) >>\n",
    "    Linear[Float](\"Layer_1/Linear\", 64) >> ReLU[Float](\"Layer_1/Activation\", 0.001f) >>\n",
    "    Linear[Float](\"Layer_2/Linear\", 32) >> ReLU[Float](\"Layer_2/Activation\", 0.001f) >>\n",
    "    Linear[Float](\"OutputLayer/Linear\", 10)\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss/CrossEntropy\") >> Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.AdaGrad()\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)\n",
    "\n",
    "// Create an estimator and train the model.\n",
    "val estimator = InMemoryEstimator(model)\n",
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(5000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "println(s\"Train accuracy = ${accuracy(dataSet.trainImages, dataSet.trainLabels)}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataSet.testImages, dataSet.testLabels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformImagesForPrediction(imagefilePath: String, numChannel: Int, s: Session = Session()): Tensor[UByte] = {\n",
    "    val tensorImageOuts = TImage.decodePng(Files.readFile(imagefilePath), numChannel)\n",
    "    s.run(fetches = tf.reshape(tensorImageOuts, Shape(1,28,28)))\n",
    "}\n",
    "\n",
    "def runPrediction(imagePath: String): String = {\n",
    "    val imageTest = transformImagesForPrediction(imagePath, 1)\n",
    "    val imageToDisplay = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(tf.reshape(imageTest, Shape(28, 28, 1)))))\n",
    "    //Image(imageToDisplay.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    val predictions = estimator.infer(() => imageTest.toFloat)\n",
    "    s\"Le chiffre trouvé est : ${predictions.argmax(1).toInt.scalar}\"\n",
    "}\n",
    "\n",
    "//runPrediction(\"../resources/images/output-onlinepngtools.png.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawOwnNumber(id: String) {\n",
    "    val htmlCode = JFiles.readString(Paths.get(\"../resources/drawing.html\"))\n",
    "    kernel.publish.display(almond.interpreter.api.DisplayData(Map(\"text/html\" -> htmlCode.replace(\"nameCommandToChange\", id))))\n",
    "}\n",
    "val id = java.util.UUID.randomUUID().toString // random ID use to synchronize communication between JS code and Scala code\n",
    "drawOwnNumber(id)\n",
    "kernel.publish.html(\"\", id)\n",
    "kernel.comm.receiver(id) { data =>\n",
    "    kernel.publish.updateHtml(\"Waiting\", id)\n",
    "    val nameImage = java.util.UUID.randomUUID().toString\n",
    "    val base64 = data.drop(34).dropRight(2)\n",
    "    val bis = new ByteArrayInputStream(Base64.getDecoder().decode(base64))\n",
    "    val bImage2 = ImageIO.read(bis)\n",
    "    val tmp = bImage2.getScaledInstance(28, 28, JImage.SCALE_SMOOTH)\n",
    "    val dimg = new BufferedImage(28, 28, BufferedImage.TYPE_INT_ARGB)\n",
    "    val g2d = dimg.createGraphics()\n",
    "    g2d.drawImage(tmp, 0, 0, null)\n",
    "    g2d.dispose()\n",
    "    ImageIO.write(dimg, \"png\", new File(s\"../resources/images/$nameImage.png\") )\n",
    "    val result = runPrediction(s\"../resources/images/$nameImage.png\")\n",
    "    kernel.publish.updateHtml(s\"$result\", id)\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
