{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2 : MNIST with Multiple Layer Perceptron (MLP)</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">(Almond 0.8.1, Scala 2.12.8)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.Paths\n",
    "\n",
    "import org.platanios.tensorflow.api._\n",
    "\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.Indexer._\n",
    "import org.platanios.tensorflow.api.core.client.Session\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import org.platanios.tensorflow.api.learn.layers.{ Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean }\n",
    "import org.platanios.tensorflow.api.learn.{ Model, StopCriteria }\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{\n",
    "def displayNumberMNIST(nb: Int) {\n",
    "    val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "    val images = dataset.trainImages\n",
    "    val imagesToDisplay = images.slice(0 :: nb, ::, ::)\n",
    "    for (index <- 0 until nb) {\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imagesToDisplay(index).reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "displayNumberMNIST(20)\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataset.trainImages.toFloat)\n",
    "\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)\n",
    "\n",
    "// Create the MLP model.\n",
    "val input = Input(FLOAT32, Shape(-1, 28, 28))\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >>\n",
    "    Linear[Float](\"Layer_0\", 256) >> ReLU[Float](\"Layer_0/Activation\") >>\n",
    "    Linear[Float](\"Layer_1\", 256) >> ReLU[Float](\"Layer_1/Activation\") >>\n",
    "    Linear[Float](\"OutputLayer\", 10)\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.Adam()\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)\n",
    "\n",
    "// Create an estimator and train the model.\n",
    "val estimator = InMemoryEstimator(model)\n",
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(5000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "println(s\"Train accuracy = ${accuracy(dataset.trainImages, dataset.trainLabels)}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataset.testImages, dataset.testLabels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val images = dataset.testImages\n",
    "\n",
    "def inferOnSelectedImage(indexes: Seq[Int], images: Tensor[UByte]) {\n",
    "    indexes.foreach { index => \n",
    "        val imageToInfer = images.slice(index, ::, ::).reshape(Shape(1, 28, 28))\n",
    "        val predictions = estimator.infer(() => imageToInfer.toFloat)\n",
    "        println(s\"Label infered: ${predictions.argmax(1).scalar}\")\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imageToInfer.reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "\n",
    "inferOnSelectedImage((30 to 40), images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
