{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2 : MNIST with Multiple Layer Perceptron (MLP)</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">(Almond 0.8.0, Scala 2.12.8)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"darwin-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{ Files => JFiles, Paths, Path }\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.{Image => JImage}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{BufferedInputStream, File, FileInputStream, ByteArrayOutputStream, IOException}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.collection.mutable.ListBuffer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.image.BufferedImage\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.Color\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.awt.image.BufferedImage\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjavax.imageio.ImageIO\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Base64\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.PrintWriter\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.io.Source\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.ByteArrayInputStream\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.tf\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.tensors.Tensor\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.Shape\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.client.{Session, FeedMap}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.types.DataType\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.{Shape, types}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.language.postfixOps\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.types.UByte\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.Output\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.layers.{Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, ScalarSummary}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.{Model, StopCriteria, Configuration}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.hooks.{SummarySaver, StepHookTrigger, CheckpointSaver}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.config.TensorBoardConfig\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.util.Base64\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.types.UByte\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.Output\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.Paths\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
    "import java.nio.file.{ Files => JFiles, Paths, Path }\n",
    "import java.awt.{Image => JImage}\n",
    "import java.io.{BufferedInputStream, File, FileInputStream, ByteArrayOutputStream, IOException}\n",
    "import scala.io.Source\n",
    "import scala.collection.mutable.ListBuffer\n",
    "import java.awt.image.BufferedImage\n",
    "import java.awt.Color\n",
    "import java.awt.image.BufferedImage\n",
    "import javax.imageio.ImageIO\n",
    "import scala.util.Random\n",
    "import java.util.Base64\n",
    "import java.io.PrintWriter\n",
    "import scala.io.Source\n",
    "import java.io.ByteArrayInputStream\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.client.{Session, FeedMap}\n",
    "import org.platanios.tensorflow.api.core.types.DataType\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import java.nio.file.{Files, Paths}\n",
    "import org.platanios.tensorflow.api.core.{Shape, types}\n",
    "import scala.language.postfixOps\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
    "import org.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
    "import org.platanios.tensorflow.api.ops.Output\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.learn.layers.{Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, ScalarSummary}\n",
    "import org.platanios.tensorflow.api.learn.{Model, StopCriteria, Configuration}\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.api.learn.hooks.{SummarySaver, StepHookTrigger, CheckpointSaver}\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "import java.util.Base64\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.implicits.helpers.{OutputStructure, OutputToDataType, OutputToShape}\n",
    "import org.platanios.tensorflow.api.learn.ClipGradientsByGlobalNorm\n",
    "import org.platanios.tensorflow.api.ops.Output\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import java.nio.file.Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-11 09:22:31.627 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file '../resources/dataset/train-images-idx3-ubyte.gz'.\n",
      "2019-09-11 09:22:33.114 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file '../resources/dataset/train-labels-idx1-ubyte.gz'.\n",
      "2019-09-11 09:22:33.119 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file '../resources/dataset/t10k-images-idx3-ubyte.gz'.\n",
      "2019-09-11 09:22:33.179 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file '../resources/dataset/t10k-labels-idx1-ubyte.gz'.\n",
      "2019-09-11 09:22:33.180 [scala-interpreter-1] INFO  MNIST Data Loader - Finished loading the MNIST dataset.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVQokWNgGMyAWUhIqK5jvdSy/9/rGRgYGFhgEnJsVjYCwQwMDAxPJgV+vniQgYGBgREqZ7iXH8r6l/SV4dn7m8gmCt3++/fv37/Htn3/iMW+gDnZf/+e5WbQnoXNNXyMs/5GoQoxwVmf/n9kSGFiwAW49/11wynJoPzx4YIcRlyygR/+/i2XxCWru+vv32nSuGQFYv/83Y3b4p9/fzpAmSyoMnohpiwM1w5h06Q+5enfv39/bcMiJVF09+/fv39P+mFKiTtd/fv3799jgZiBJLT69t+/f/8eDuDEkDJf8+jv379/v7Ryo4qzMDAwMAQGMjBc3/y35wM2V1IfAABFF16AiykZfAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA/0lEQVQokWNgGHhgPP/vfCMccgbv/vz58xa7nNnjv3/ev/xjyYYpxWXz4M/fP6dC/vytgggwIUnOPCDDwMBgxHOQQRdD0tibkfFQKeOL85OYGLG5ZTOPd6UoA8Pfz2gOVlv69+WFEAj775+lKHLsm/58cBeWgUkeRpG0/PPHHs5Blzz2dx+C8//vEWTX+hj834SQ/Pf/ArLG0D/PJOHWt//dxYMqeR8u1/znoTsDquREKMtg6Z+1DKgg7O9DCKPo3d9FaHIMoX9+TjKQDd308O/95RaYkn/+PL3+58+fI03oUgwMMsf//Pn758/LiZhSDAwMkg1//v7pVcUqR1cAAKxwbkRl0258AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVQokWNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksRyG3IyAAAAAASUVORK5CYII="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVQokWNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0TUCHhCAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA3ElEQVQokWNgGJ7AfMqlv38Lw6eYY5ELf/Hn795Lf/78XYEhxWL56c8+R1aebX/+lmBIJvz5s52PgSHmz5+HouhyLX//TOJjYGC4/uePP7pc3d/vGzgZGDj8vv5tRJcTePFnAwMDg8rJP39WcqNLiv35IydWfvTj3z+/fTFcI/D8z98/f/48evznORY/mr/+e7NLS+LAn34skhBg9/9vLk5J979/MPyIAKiSTKg6UZWiSirjkzzMxIjbSoZbfyyQeMyokp/9lM+8xqWTb8efVRhhi5Cd/EcLj7VIAADRUlW1zfEENAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABD0lEQVQokWNgGGSAEY3Py+Mt1vsTq1LF6Rf+/PkzCZuUxowvf/4+uPznhQaGFP+M93/+/Lkhr/rnjw2GZMKfP3/+3JRlQJJkgkuGMjA8WO36mAHJTBY4KzVt151XDAwM4ti9BQFzEcayoEjkcTP+12U4dhxTC5fp5r9////9+0QZQ4rV7PGfz09Wffrz53kpG5ocm9+fP7XWDEIX/vz58yecHVVf+58/WwQYRE///d649s+fHU6GhnA55o4/H7MEGUxP/LnhyMDnsfjjnz/34ZKZfz5FCHmu+vKnTpaBgYGBIXLLFlW45PM/X8/e+PPnTw0zFo+f//Pnz59NJSqovoZGNm+A0at5739h0Ta4AABroXIj000W8AAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAk0lEQVQokWNgGGAw8f9leVxyCm///nFHFmBCYr8+hKYaWfLrQzySAvp4JLnkGBhMkV3EjMT+zO/A4HD/FC73/v3zJweHsQwMTIyMyFwWFMl//3E6CAOQIMnEyGiHU+nfP3/+aCG4zCiS4iYMDH934DD2Bj4XMNz6+/e/Mg6dDFf///+Hy7UMs1B4aJLXruO1lQ4AAJqZJAAJl0BgAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABEklEQVQokc2RMS+DURiFn/ullKXC1KWJyVId2ARBQpqUHyBRC0NjsPsPNktj0F9QEgYiIvEDJG3CYhEpMTBI2qEk5+YzfP1uuD6bwVnum3ve877n5IV/jLH8Vmittfao36fyuw8tWUmSahmPPJEUk5oGIOXIixIvNRMyNZewMZXLZQEyLame9pR6jN7iMDx9JFtevZTk+4mwdtuVdD2IN3Z0fRFmQmjvnHY9TeE+jnLs/gJXGWOMCYwxKyUXIC5u5svn78DmdrJRAIYkpwx8svizv2+5536j/UUZYfZMOYCR8pvUWXAeAWiOU+0AS5MhV9XD78pm71Kyz/sD/sqJA0nSXWOvkBAgXXlVvZL9Jd4f4xPJmHJ5awbmxgAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAc0lEQVQokWNgGMyA1f4obkmRf88kkPlMqNIS+CQZGfBI/ufEI8lgjFPyz0cGZZySHw6jGoNuLF5JYXySfrgl9+Mz9hEDqzxOyT8MjOy43Xft3zTckhM+cuA0loHh/y88knwBuI199l0Dt85Dt77j1kktAADVQhZzaEXtdgAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA7klEQVQokc3QsUtCURiG8QdRFIKEoCHIGtouSM4SRn9CixE0REtjS4tu0tLm4tIS4tLeFqE0FNjukIqLDrchCBq85H1Pt6Gl7vGs4bed78cDHwcWZtodgMRcqxeHzu4y+Cg78UH39rJ0twJw+NbftvHF7AD0ov2f95+DplEGKGx8ZezwIuytwtKNnlKW5V6DXeBKY7vLD1UHzj91GqfksYlMt5pee55dW92RZPpSdyLfsoMw8PcKbckonGzFsDM6AbxHGakVL89yAKV3lT1v2T4WyDbMYC4AVOSvu2xzFNac4UDN2ObXxze5dYb/N9+FeFNxHVVKdAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA60lEQVQokWNgoD9gRGJr+aSevsAw4Rc2demf/v379++fE1ZDhF78+/fv3793bnARZoTk9y+OrI/4GThe78Kq9/y/S//+/VPC7rqQc//+/funicPtEhf//fu3Gs5lQZaL1tNhYGA4ik2bxrVf//6h2MmEkNRUhBhTgNXGvG///uG0c9JtAQaWyXw4HMvAwMDY8O+2PC5J9n//rsngkuz6968EXUx4YxQDAwMDg+QHLMG35N91exUG48hz//51c6BLWh799+/elo///v29yo1pV0/mv3///v379wZZEObPEnYeBoNIho9umProCwCLf192wYi1WQAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAoElEQVQokWNgGN5AXqPx1av5WKVcpr3/9/fv3+tYpOac/Pfv38dpSRyYUsKz/r05Hawuh9XICX8n8mB3B1fjPT9/LMYxMDAwMLT9XY5LioHh/z8/nHIMJ/8+csUuY87GINTw96MmFinJs69jGBhE/v61wiL5/GsOAwNDy9+dfFgkK7/++/fv5r/7RiiizBDqyK83Et84D8Rd/4/bvUMaAAChYzmwwkf0uAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDklEQVQokc2RvS9DYRjFT3030TChi6TuYBJKkFgkNWlCYiHRWfwHBglmTf8AH4lRrIauV0fEjbSTNgaLRCQGHSiuH8N1w1tvN4MzPXl/z3lzTh7pnykiqXOpNhbLFG4l3R1f1C1k+ZZfWk8YzusB6aEkqTzYnZTm8j+dTtpx4sEYu4HdRhGW4Xncjtp2niBpZ6kDeFntsLKJN6CWbrXCXFDmfGPIAqfy919dcz0W3D86u/8OcNJkT5U5BVizQ7UUgD1J0m+/70mqmDC+uRgMzcOSf2bs9xXpkiT1bgNF87MjGIlK0a1H+KhOm3AF8FzXA6jO1MVIHIbnfs1Oho+RcGhfSFXmdSW3fNmg45/pE8oAf9yKthHTAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+UlEQVQokdWPoUtDYRTFTxC0CIJhQcS0l8aYGPSF8TBOhWX/gxXZUxSbQcOKzVWbJmGMLQ/TXDVtZbyhbGEWnwtazvEzCML7tq+teNLl/rjnngPMTV704mQ3b6w7UKotPq86LBvU2a7j0Cd16MwiFV1hrthcc7Gnz346uVn4m4rb5uHLAVfywPsQQHkdp7bp8qPRDnByHEnGfn1ADdLI1chJV52N5OERh5fw7jW+2wzUTcICeYFUg3F1MdOLq0nXcxJokwF88tp6WVENuZFCeJHCqSrGAN8m+7o0yH/YTXzSL8Wkxns2ArYmFEnaWX613xJ5Gwaz2P/QDwv6bXkRmxmeAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAbElEQVQokWNgGMSAccUnGZySXE/+paAIMCGxv91iEMMpyTCVQQO3pbL/fkji1MnAyOaHW/I/AxtuSTRAgiQjPsn/+I29hE/yLpkOYmBgxyfphVPy5TU8xv76zuCK29gLDDy4nadwPAO3JNUAAMpqE3GRwb4KAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA5UlEQVQokd3PMUuCURjF8aODg1AoOdjk+CbOTg0SRps0tNnukNHi1BcIHFwbaowgGl3EoJBGwaFFCsrKT6BBGPW/5CLF+3KfL+CZ7uV3H+5zpKVJLHJvJPL7eix4Xpbq1z8A38MIrPfG4ymuD8B72LZfAQjWgq036ITxBvg8LEo6hedMyHY+YLQpSWpDKzzYhfuyJKWrk8XpP3uDu6wk6Rgesp4iklSZ8XVgmBzULDv5dS4wLNFx1ON+S9ZwFym/rVzBkTGnPDxZy2ycM8xZeAnRhn9/FFZ1dmsNNnmxGkpldk3zZg5Mtl9wS8y6WQAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+klEQVQokWNgGMQgdsnlX78O8WOTEtnw9+2WLZ//XcMmeeZNuxADg8anP3WYcq5/lzMwMDAwNP27DxdjgjFY76xgYGBgYFjDwMGHoZODC0Kr//uXgaHzxzcIfe8agyqGJAz8/o1gY0iyczB8xnQuA9xOCwYGEecadQwpduWkf/8uzD3/8N/HBQwMjDBhTjFjcycGTi0GBoa/TxgWbH2L8C5n57V///79+/Dk179/s4zQjNv57/vmSc42Mgw3/t3hQbfr/z1DBgYGBpbOLy/Q9TEw/DvHwsDAwLH533cHTA/c+DdvY1PC1T/HDbF5r/n7z58/V3tgkxpEAACefFmwxt84vAAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA90lEQVQokWNgGAKA+/RTBQYGBgYGFjQJKVGG947GN99iSOrmyjOoyTF0aDE+ZcMwLu/v37/fFj75+/dfDIZcw9e/8zpFGQxe/n3JgSHZ/e++JAODyqp/X7IwHWl+5e9CbqlNf98UYvEB++y/TwLu//2bi9V/vX///v33d5YsVsm8v3///tushlWOefW/f/82I4sgBcKKoP8MDP+x6pOq/vf39Jy/J7BKxv79V8kb+3ceNjmH9399OBRu/61DFmSC0q78h7b89eFnfINN8v///6wBE5nmTMNm7My/Kw/8/euL1TkMBX///nvTyIldUrDs835sAU4LAABuqmGnMJ0XsgAAAABJRU5ErkJggg=="
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAw0lEQVQokWNgoA9QWvlLA5ec1ae7/YI45Ly/93Ph0qf6dQcTLjmOAyf4cDqm+7sMTjn259txyjHUfjbCLXl4B24529+aDAwMDtpYJWdcYmdIePvvezY2yV8hDGz3Q3jDv3lgymn/C2CwmM7AwDD5IKak8z9NBl5hBgYGrb8wIRYk6ScMnyEUDCCCkpERyrD/jCn5/z+EZs1YjGmn5NNMBgYGBtY5V0WweCX7WyafYfzNi9JY5BgYsr/9/fuhiQ2r3OAAAO+sNJpHegvvAAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAw0lEQVQokWNgGKZAKPPx379V2OUsj//98+fPn/nY5EQu/3kxw3P5n+tsWCSP/tnGwMCg+vqzPlSACUnyO8NGBgYGBoZPb6ACLEiSjIzvOZQTjF9EPcVi7Is/J07++ROC3bFXv/75++eTFnZJBouQv38W4JBjYND9+0cNicuEIqnDxMiAU/L7vwO/cJmqufkFDrcyMPA//FOM0zkz/yzBKefy9bM/LjmFt1+DcMlxTvmzEqehWX+PsOOSM3vSKINTI1YAAAjUQy8/OeT7AAAAAElFTkSuQmCC"
     },
     "metadata": {
      "height": 100,
      "width": 100
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{\n",
    "def displayNumberMNIST(nb: Int) {\n",
    "    val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "    val images = dataset.trainImages\n",
    "    val imagesToDisplay = images.slice(0 :: nb, ::, ::)\n",
    "    for (index <- 0 until nb) {\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imagesToDisplay(index).reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "displayNumberMNIST(20)\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-09-10 16:53:23.516 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file '../resources/dataset/train-images-idx3-ubyte.gz'.\n",
      "2019-09-10 16:53:25.180 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file '../resources/dataset/train-labels-idx1-ubyte.gz'.\n",
      "2019-09-10 16:53:25.184 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting images from file '../resources/dataset/t10k-images-idx3-ubyte.gz'.\n",
      "2019-09-10 16:53:25.246 [scala-interpreter-1] INFO  MNIST Data Loader - Extracting labels from file '../resources/dataset/t10k-labels-idx1-ubyte.gz'.\n",
      "2019-09-10 16:53:25.248 [scala-interpreter-1] INFO  MNIST Data Loader - Finished loading the MNIST dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataset\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mplatanios\u001b[39m.\u001b[32mtensorflow\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mimage\u001b[39m.\u001b[32mMNISTDataset\u001b[39m = \u001b[33mMNISTDataset\u001b[39m(\n",
       "  MNIST,\n",
       "  Tensor[UByte, [60000, 28, 28]],\n",
       "  Tensor[UByte, [60000]],\n",
       "  Tensor[UByte, [10000, 28, 28]],\n",
       "  Tensor[UByte, [10000]]\n",
       ")\n",
       "\u001b[36mtrainImages\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainLabels\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = Dataset[TensorSlicesDataset]\n",
       "\u001b[36mtrainData\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mdata\u001b[39m.\u001b[32mDataset\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m])] = Dataset[TensorSlicesDataset/Zip/Repeat/Shuffle/Batch/Prefetch]\n",
       "\u001b[36minput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@12c8cc33\n",
       "\u001b[36mtrainInput\u001b[39m: \u001b[32mInput\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]] = org.platanios.tensorflow.api.learn.layers.Input@eae3211\n",
       "\u001b[36mlayer\u001b[39m: \u001b[32mlearn\u001b[39m.\u001b[32mlayers\u001b[39m.\u001b[32mCompose\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "  \u001b[33mCompose\u001b[39m(\n",
       "    \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "    \u001b[33mCompose\u001b[39m(\n",
       "      \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "      \u001b[33mCompose\u001b[39m(\n",
       "        \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "        \u001b[33mCompose\u001b[39m(\n",
       "          \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "          \u001b[33mCompose\u001b[39m(\n",
       "            \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "            \u001b[33mCompose\u001b[39m(\n",
       "              \u001b[32m\"Input/Flatten\"\u001b[39m,\n",
       "              \u001b[33mFlatten\u001b[39m(\u001b[32m\"Input/Flatten\"\u001b[39m),\n",
       "              \u001b[33mLinear\u001b[39m(\n",
       "                \u001b[32m\"Layer_0\"\u001b[39m,\n",
       "                \u001b[32m128\u001b[39m,\n",
       "                true,\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                ),\n",
       "                \u001b[33mRandomNormalInitializer\u001b[39m(\n",
       "                  Tensor[Float, []],\n",
       "                  Tensor[Float, []],\n",
       "                  \u001b[32mNone\u001b[39m\n",
       "                )\n",
       "              )\n",
       "            ),\n",
       "            \u001b[33mReLU\u001b[39m(\u001b[32m\"Layer_0/Activation\"\u001b[39m, \u001b[32m0.1F\u001b[39m)\n",
       "          ),\n",
       "          \u001b[33mLinear\u001b[39m(\n",
       "            \u001b[32m\"Layer_1\"\u001b[39m,\n",
       "            \u001b[32m64\u001b[39m,\n",
       "            true,\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m),\n",
       "            \u001b[33mRandomNormalInitializer\u001b[39m(Tensor[Float, []], Tensor[Float, []], \u001b[32mNone\u001b[39m)\n",
       "...\n",
       "\u001b[36mloss\u001b[39m: \u001b[32mlearn\u001b[39m.\u001b[32mlayers\u001b[39m.\u001b[32mCompose\u001b[39m[(\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m]] = \u001b[33mCompose\u001b[39m(\n",
       "  \u001b[32m\"Loss\"\u001b[39m,\n",
       "  \u001b[33mSparseSoftmaxCrossEntropy\u001b[39m(\u001b[32m\"Loss\"\u001b[39m),\n",
       "  \u001b[33mMean\u001b[39m(\u001b[32m\"Loss/Mean\"\u001b[39m, \u001b[32mnull\u001b[39m, false)\n",
       ")\n",
       "\u001b[36moptimizer\u001b[39m: \u001b[32mops\u001b[39m.\u001b[32mtraining\u001b[39m.\u001b[32moptimizers\u001b[39m.\u001b[32mGradientDescent\u001b[39m = org.platanios.tensorflow.api.ops.training.optimizers.GradientDescent@1680df27\n",
       "\u001b[36mmodel\u001b[39m: \u001b[32mlearn\u001b[39m.\u001b[32mSupervisedTrainableModel\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m] = org.platanios.tensorflow.api.learn.Model$$anon$1@443ec68e\n",
       "\u001b[36mestimator\u001b[39m: \u001b[32mInMemoryEstimator\u001b[39m[\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]), \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mFloat\u001b[39m, (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], (\u001b[32mOutput\u001b[39m[\u001b[32mFloat\u001b[39m], \u001b[32mOutput\u001b[39m[\u001b[32mLong\u001b[39m]))] = org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator@6241d400"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataset.trainImages.toFloat)\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)\n",
    "\n",
    "// Create the MLP model.\n",
    "val input = Input(FLOAT32, Shape(-1, 28, 28))\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >>\n",
    "    Linear[Float](\"Layer_0\", 128) >> ReLU[Float](\"Layer_0/Activation\") >>\n",
    "    Linear[Float](\"Layer_1\", 64) >> ReLU[Float](\"Layer_1/Activation\") >>\n",
    "    Linear[Float](\"Layer_2\", 32) >> ReLU[Float](\"Layer_2/Activation\") >>\n",
    "    Linear[Float](\"OutputLayer\", 10)\n",
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.GradientDescent(1e-6f)\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)\n",
    "\n",
    "// Create an estimator and train the model.\n",
    "val estimator = InMemoryEstimator(model)\n",
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(1000)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "println(s\"Train accuracy = ${accuracy(dataSet.trainImages, dataSet.trainLabels)}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataSet.testImages, dataSet.testLabels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/*def transformImagesForPrediction(imagefilePath: String, numChannel: Int, s: Session = Session()): Tensor[UByte] = {\n",
    "    val tensorImageOuts = TImage.decodePng(Files.readFile(imagefilePath), numChannel)\n",
    "    s.run(fetches = tf.reshape(tensorImageOuts, Shape(1,28,28)))\n",
    "}\n",
    "\n",
    "def runPrediction(imagePath: String): String = {\n",
    "    val imageTest = transformImagesForPrediction(imagePath, 1)\n",
    "    val imageToDisplay = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(tf.reshape(imageTest, Shape(28, 28, 1)))))\n",
    "    Image(imageToDisplay.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    val predictions = estimator.infer(() => imageTest.toFloat)\n",
    "    s\"Le chiffre est : ${predictions.argmax(1).toInt.scalar}\"\n",
    "}*/\n",
    "dataSet.trainImages.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
