{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(\"org.platanios\", \"tensorflow_2.12\"),\n",
    "    version = \"0.4.1\",\n",
    "    // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "    attributes = coursier.Attributes(\"\", \"darwin-cpu-x86_64\")\n",
    "  )\n",
    ")\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.layers._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.data.image.MNISTLoader\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.core.client.FeedMap\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.tensorflow.framework.GraphDef\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.Files\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.platanios.tensorflow.api.ops.Image\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.learn._\n",
    "import org.platanios.tensorflow.api.learn.layers._\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.core.client.FeedMap\n",
    "import org.tensorflow.framework.GraphDef\n",
    "\n",
    "import org.platanios.tensorflow.api.ops.Files\n",
    "import org.platanios.tensorflow.api.ops.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mjava.net.URL\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36msys.process._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.io.{BufferedInputStream, File, FileInputStream}\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import java.net.URL\n",
    "import sys.process._\n",
    "import java.io.{BufferedInputStream, File, FileInputStream}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model to be served\n",
    "\n",
    "### We download the published Tensorflow model from a public URL\n",
    "\n",
    "See https://github.com/tensorflow/models for reference on available models from research community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mcacheDir\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"/Users/xavier/data/models/tmp\"\u001b[39m\n",
       "\u001b[36mmodelName\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"ssd_mobilenet_v2_coco_2018_03_29\"\u001b[39m\n",
       "\u001b[36marchiveFilename\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"ssd_mobilenet_v2_coco_2018_03_29.tar.gz\"\u001b[39m\n",
       "\u001b[36mmodelURL\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v2_coco_2018_03_29.tar.gz\"\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cacheDir = sys.env(\"HOME\") + \"/data/models/tmp\"\n",
    "val modelName = \"ssd_mobilenet_v2_coco_2018_03_29\"\n",
    "val archiveFilename = s\"${modelName}.tar.gz\"\n",
    "\n",
    "val modelURL = s\"http://download.tensorflow.org/models/object_detection/${archiveFilename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new URL(modelURL) #> new File(s\"${cacheDir}/${archiveFilename}\") !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the model archive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s\"tar -xzf ${cacheDir}/${archiveFilename} -C ${cacheDir}\" !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\n",
      "frozen_inference_graph.pb\n",
      "model.ckpt.data-00000-of-00001\n",
      "model.ckpt.index\n",
      "model.ckpt.meta\n",
      "mscoco_label_map.pbtxt\n",
      "pipeline.config\n",
      "saved_model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres5\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m0\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s\"ls ${cacheDir}/${modelName}\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model in a Tensorflow Session\n",
    "\n",
    "In the extracted directory, named after the `modelName`, we are interested in loading the `frozen_inference_graph.pb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmodelGraphPath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"/Users/xavier/data/models/tmp/ssd_mobilenet_v2_coco_2018_03_29/frozen_inference_graph.pb\"\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val modelGraphPath = s\"${cacheDir}/${modelName}/frozen_inference_graph.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mgraphDef\u001b[39m: \u001b[32mGraphDef\u001b[39m = \u001b[32m<lazy>\u001b[39m\n",
       "\u001b[36mgraph\u001b[39m: \u001b[32mGraph\u001b[39m = org.platanios.tensorflow.api.core.Graph@b436c0d\n",
       "\u001b[36msession\u001b[39m: \u001b[32mSession\u001b[39m = org.platanios.tensorflow.api.core.client.Session@47766d4c"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lazy val graphDef = GraphDef.parseFrom(\n",
    "    new BufferedInputStream(new FileInputStream(new File(modelGraphPath))))\n",
    "val graph = Graph.fromGraphDef(graphDef)\n",
    "val session = Session(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes to access the model signature (input and responses)\n",
    "\n",
    "`image_tensor` is the tensor representing the input images, with 3-channels colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mimagePlaceholder\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mUByte\u001b[39m] = \u001b[33mOutput\u001b[39m(image_tensor, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mres8_1\u001b[39m: \u001b[32mShape\u001b[39m = [?, ?, ?, 3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val imagePlaceholder = graph.getOutputByName(\"image_tensor:0\").toUByte\n",
    "imagePlaceholder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_detections` is the number of detected objects\n",
    "\n",
    "`detection_boxes` are the corrdinates of detected objects\n",
    "\n",
    "`detection_scores` are a probability-like score for each object\n",
    "\n",
    "`detection_classes` are the class label for each detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdetectionBoxes\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mAny\u001b[39m] = \u001b[33mOutput\u001b[39m(detection_boxes, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mdetectionScores\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mAny\u001b[39m] = \u001b[33mOutput\u001b[39m(detection_scores, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mdetectionClasses\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mAny\u001b[39m] = \u001b[33mOutput\u001b[39m(detection_classes, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mnumDetections\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mAny\u001b[39m] = \u001b[33mOutput\u001b[39m(num_detections, \u001b[32m0\u001b[39m)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val detectionBoxes = graph.getOutputByName(\"detection_boxes:0\")\n",
    "val detectionScores = graph.getOutputByName(\"detection_scores:0\")\n",
    "val detectionClasses = graph.getOutputByName(\"detection_classes:0\")\n",
    "val numDetections = graph.getOutputByName(\"num_detections:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes to feed the graph with an image file path\n",
    "\n",
    "A Placeholder to provide a filepathe is the input, and the file is opened and decoded as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mimgTensor\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mUByte\u001b[39m] = \u001b[33mOutput\u001b[39m(DecodePng_1, \u001b[32m0\u001b[39m)\n",
       "\u001b[36mfileNamePlaceholder\u001b[39m: \u001b[32mOutput\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mOutput\u001b[39m(Placeholder_1, \u001b[32m0\u001b[39m)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (imgTensor, fileNamePlaceholder) = tf.createWith(graph = graph) {\n",
    "    val fileNamePlaceholder = tf.placeholder[String]()\n",
    "    val fileTensor = Files.readFile(fileNamePlaceholder)\n",
    "    val imgTensor = Image.decodePng(fileTensor, 3)\n",
    "    (imgTensor, fileNamePlaceholder)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Service function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdetectObjects\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detectObjects(file: File) = {\n",
    "    \n",
    "    // Feed the image file to get the Images Tensor\n",
    "    val fileNameTensor = Tensor.fill(Shape())(file.getAbsolutePath())\n",
    "    val feedImg = FeedMap(fileNamePlaceholder, fileNameTensor)\n",
    "    val imageOuts: Tensor[UByte] =\n",
    "      session.run(fetches = imgTensor, feeds = feedImg)\n",
    "\n",
    "    // Retain image sizes to format output later\n",
    "    val width = imageOuts.shape(1)\n",
    "    val height = imageOuts.shape(0)\n",
    "\n",
    "    // Feed with Images to compute detections:\n",
    "    val feeds = FeedMap(imagePlaceholder, imageOuts.slice(NewAxis, ---))\n",
    "    val Seq(boxes, scores, classes, num) =\n",
    "      session.run(\n",
    "        fetches =\n",
    "          Seq(detectionBoxes, detectionScores, detectionClasses, numDetections),\n",
    "        feeds = feeds)\n",
    "    \n",
    "  val labelList =\n",
    "      for {\n",
    "        i <- 0 until num(0).scalar.asInstanceOf[Float].toInt\n",
    "        labelId = classes(0, i).toFloat.scalar.toInt\n",
    "        //label = labelMap.getOrElse(labelId, \"unknown\")\n",
    "        //if setOfClasses.isEmpty || setOfClasses.contains(label)\n",
    "\n",
    "        box = boxes(0, i).toFloat.entriesIterator.toSeq\n",
    "        x1 = (box(1) * width).toInt\n",
    "        y1 = (box(0) * height).toInt\n",
    "        x2 = (box(3) * width).toInt\n",
    "        y2 = (box(2) * height).toInt\n",
    "        labelBox = (x1, y1, x2 - x1 + 1, y2 - y1 + 1)\n",
    "        score = scores(0, i).toFloat.scalar\n",
    "      } yield (labelId, score, labelBox)\n",
    "    labelList.toSeq\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres14\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mimmutable\u001b[39m.\u001b[32mSeq\u001b[39m[(\u001b[32mInt\u001b[39m, \u001b[32mFloat\u001b[39m, (\u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m, \u001b[32mInt\u001b[39m))] = \u001b[33mVector\u001b[39m(\n",
       "  (\u001b[32m1\u001b[39m, \u001b[32m0.9714311F\u001b[39m, (\u001b[32m141\u001b[39m, \u001b[32m38\u001b[39m, \u001b[32m368\u001b[39m, \u001b[32m722\u001b[39m)),\n",
       "  (\u001b[32m1\u001b[39m, \u001b[32m0.96262753F\u001b[39m, (\u001b[32m554\u001b[39m, \u001b[32m101\u001b[39m, \u001b[32m328\u001b[39m, \u001b[32m651\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detectObjects(new File(sys.env(\"HOME\") + \"/Downloads/baywatch.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Labels ids in labels\n",
    "\n",
    "We need a mapping between class id and class name for detections. This is provided as protobuf data and message definitions:\n",
    "\n",
    "See https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmapFilename\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"mscoco_label_map.pbtxt\"\u001b[39m\n",
       "\u001b[36mmapUrl\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/mscoco_label_map.pbtxt\"\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mapFilename = \"mscoco_label_map.pbtxt\"\n",
    "val mapUrl = s\"https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/data/${mapFilename}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new URL(mapUrl) #> new File(s\"${cacheDir}/${modelName}/${mapFilename}\") !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                         \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mobject_detection.protos.string_int_label_map.{StringIntLabelMap,StringIntLabelMapItem}\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`default:models_proto_2.12:0.1.0-SNAPSHOT`\n",
    "import object_detection.protos.string_int_label_map.{StringIntLabelMap,StringIntLabelMapItem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                  \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m_root_.io.circe.{Decoder, Encoder}\n",
       "\n",
       "\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mDetection\u001b[39m\n",
       "defined \u001b[32mobject\u001b[39m \u001b[36mDetection\u001b[39m"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`io.circe:circe-core_2.12:0.10.1`\n",
    "import $ivy.`io.circe:circe-generic_2.12:0.10.1`\n",
    "import $ivy.`io.circe:circe-parser_2.12:0.10.1`\n",
    "import _root_.io.circe.{Decoder, Encoder}\n",
    "\n",
    "case class Detection(`class`: String, score: Float, box: (Int, Int, Int, Int))\n",
    "\n",
    "object Detection {\n",
    "  import _root_.io.circe.generic.semiauto._\n",
    "\n",
    "  implicit lazy val encoder: Encoder[Detection] = deriveEncoder[Detection]\n",
    "  implicit lazy val decoder: Decoder[Detection] = deriveDecoder[Detection]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mlabelMap\u001b[39m: \u001b[32mcollection\u001b[39m.\u001b[32mMap\u001b[39m[\u001b[32mInt\u001b[39m, \u001b[32mString\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m88\u001b[39m -> \u001b[32m\"teddy bear\"\u001b[39m,\n",
       "  \u001b[32m5\u001b[39m -> \u001b[32m\"airplane\"\u001b[39m,\n",
       "  \u001b[32m10\u001b[39m -> \u001b[32m\"traffic light\"\u001b[39m,\n",
       "  \u001b[32m56\u001b[39m -> \u001b[32m\"broccoli\"\u001b[39m,\n",
       "  \u001b[32m42\u001b[39m -> \u001b[32m\"surfboard\"\u001b[39m,\n",
       "  \u001b[32m24\u001b[39m -> \u001b[32m\"zebra\"\u001b[39m,\n",
       "  \u001b[32m37\u001b[39m -> \u001b[32m\"sports ball\"\u001b[39m,\n",
       "  \u001b[32m25\u001b[39m -> \u001b[32m\"giraffe\"\u001b[39m,\n",
       "  \u001b[32m52\u001b[39m -> \u001b[32m\"banana\"\u001b[39m,\n",
       "  \u001b[32m14\u001b[39m -> \u001b[32m\"parking meter\"\u001b[39m,\n",
       "  \u001b[32m20\u001b[39m -> \u001b[32m\"sheep\"\u001b[39m,\n",
       "  \u001b[32m46\u001b[39m -> \u001b[32m\"wine glass\"\u001b[39m,\n",
       "  \u001b[32m57\u001b[39m -> \u001b[32m\"carrot\"\u001b[39m,\n",
       "  \u001b[32m78\u001b[39m -> \u001b[32m\"microwave\"\u001b[39m,\n",
       "  \u001b[32m84\u001b[39m -> \u001b[32m\"book\"\u001b[39m,\n",
       "  \u001b[32m61\u001b[39m -> \u001b[32m\"cake\"\u001b[39m,\n",
       "  \u001b[32m89\u001b[39m -> \u001b[32m\"hair drier\"\u001b[39m,\n",
       "  \u001b[32m1\u001b[39m -> \u001b[32m\"person\"\u001b[39m,\n",
       "  \u001b[32m74\u001b[39m -> \u001b[32m\"mouse\"\u001b[39m,\n",
       "  \u001b[32m6\u001b[39m -> \u001b[32m\"bus\"\u001b[39m,\n",
       "  \u001b[32m60\u001b[39m -> \u001b[32m\"donut\"\u001b[39m,\n",
       "  \u001b[32m85\u001b[39m -> \u001b[32m\"clock\"\u001b[39m,\n",
       "  \u001b[32m28\u001b[39m -> \u001b[32m\"umbrella\"\u001b[39m,\n",
       "  \u001b[32m38\u001b[39m -> \u001b[32m\"kite\"\u001b[39m,\n",
       "  \u001b[32m70\u001b[39m -> \u001b[32m\"toilet\"\u001b[39m,\n",
       "  \u001b[32m21\u001b[39m -> \u001b[32m\"cow\"\u001b[39m,\n",
       "  \u001b[32m33\u001b[39m -> \u001b[32m\"suitcase\"\u001b[39m,\n",
       "  \u001b[32m65\u001b[39m -> \u001b[32m\"bed\"\u001b[39m,\n",
       "  \u001b[32m9\u001b[39m -> \u001b[32m\"boat\"\u001b[39m,\n",
       "  \u001b[32m53\u001b[39m -> \u001b[32m\"apple\"\u001b[39m,\n",
       "  \u001b[32m77\u001b[39m -> \u001b[32m\"cell phone\"\u001b[39m,\n",
       "  \u001b[32m13\u001b[39m -> \u001b[32m\"stop sign\"\u001b[39m,\n",
       "  \u001b[32m41\u001b[39m -> \u001b[32m\"skateboard\"\u001b[39m,\n",
       "  \u001b[32m73\u001b[39m -> \u001b[32m\"laptop\"\u001b[39m,\n",
       "  \u001b[32m2\u001b[39m -> \u001b[32m\"bicycle\"\u001b[39m,\n",
       "  \u001b[32m32\u001b[39m -> \u001b[32m\"tie\"\u001b[39m,\n",
       "  \u001b[32m34\u001b[39m -> \u001b[32m\"frisbee\"\u001b[39m,\n",
       "  \u001b[32m64\u001b[39m -> \u001b[32m\"potted plant\"\u001b[39m,\n",
       "..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val labelMap: scala.collection.Map[Int, String] = {\n",
    "    val pbText = scala.io.Source.fromFile(s\"${cacheDir}/${modelName}/${mapFilename}\").mkString\n",
    "    val stringIntLabelMap = StringIntLabelMap.fromAscii(pbText)\n",
    "    stringIntLabelMap.item.collect {\n",
    "      case StringIntLabelMapItem(_, Some(id), Some(displayName)) =>\n",
    "        id -> displayName\n",
    "    }.toMap\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mlabelize\u001b[39m"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def labelize(detections: Seq[(Int, Float, (Int, Int, Int, Int))]) = detections.map { \n",
    "    d => d match {\n",
    "        case (id, score, box) if (labelMap.contains(id)) => Detection(labelMap(id), score, box)\n",
    "        case (id, score, box) => Detection(\"unknown\", score, box)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres20\u001b[39m: \u001b[32mSeq\u001b[39m[\u001b[32mDetection\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mDetection\u001b[39m(\u001b[32m\"person\"\u001b[39m, \u001b[32m0.9714311F\u001b[39m, (\u001b[32m141\u001b[39m, \u001b[32m38\u001b[39m, \u001b[32m368\u001b[39m, \u001b[32m722\u001b[39m)),\n",
       "  \u001b[33mDetection\u001b[39m(\u001b[32m\"person\"\u001b[39m, \u001b[32m0.96262753F\u001b[39m, (\u001b[32m554\u001b[39m, \u001b[32m101\u001b[39m, \u001b[32m328\u001b[39m, \u001b[32m651\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelize( detectObjects(new File(sys.env(\"HOME\") + \"/Downloads/baywatch.jpg\")) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an akka-http service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                        \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                         \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                          \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                              \n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.actor.ActorSystem\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.stream.{IOResult, Materializer}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.stream.scaladsl.{FileIO, Source}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.http.scaladsl.Http\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.http.scaladsl.Http.ServerBinding\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.http.scaladsl.server.Directives._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.http.scaladsl.server.Route\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.stream.ActorMaterializer\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36makka.util.ByteString\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.{Failure, Success}\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjava.nio.file.{Files, Paths}\u001b[39m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.typesafe.akka:akka-http_2.12:10.1.5`\n",
    "import $ivy.`com.typesafe.akka:akka-actor_2.12:2.5.18`\n",
    "import $ivy.`com.typesafe.akka:akka-stream_2.12:2.5.18`\n",
    "import $ivy.`de.heikoseeberger:akka-http-circe_2.12:1.21.0`\n",
    "\n",
    "import akka.actor.ActorSystem\n",
    "import akka.stream.{IOResult, Materializer}\n",
    "import akka.stream.scaladsl.{FileIO, Source}\n",
    "import akka.http.scaladsl.Http\n",
    "import akka.http.scaladsl.Http.ServerBinding\n",
    "import akka.http.scaladsl.server.Directives._\n",
    "import akka.http.scaladsl.server.Route\n",
    "import akka.stream.ActorMaterializer\n",
    "import akka.util.ByteString\n",
    "\n",
    "import scala.util.{Failure, Success}\n",
    "import java.nio.file.{Files, Paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msystem\u001b[39m: \u001b[32mActorSystem\u001b[39m = akka://main-system\n",
       "\u001b[36mmaterializer\u001b[39m: \u001b[32mActorMaterializer\u001b[39m = \u001b[33mPhasedFusingActorMaterializer\u001b[39m(\n",
       "  akka://main-system,\n",
       "  ActorMaterializerSettings(4,16,,<function1>,StreamSubscriptionTimeoutSettings(CancelTermination,5000 milliseconds),false,1000,1000,false,true,IoSettings(16384)),\n",
       "  akka.dispatch.Dispatchers@40732850,\n",
       "  Actor[akka://main-system/system/StreamSupervisor-0#1015632836],\n",
       "  false,\n",
       "  akka.stream.impl.SeqActorNameImpl@1be9bf24\n",
       ")\n",
       "\u001b[36mexecutionContext\u001b[39m: \u001b[32mconcurrent\u001b[39m.\u001b[32mExecutionContextExecutor\u001b[39m = Dispatcher[akka.actor.default-dispatcher]\n",
       "\u001b[32mimport \u001b[39m\u001b[36mde.heikoseeberger.akkahttpcirce.FailFastCirceSupport._\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[36mroute\u001b[39m: \u001b[32makka\u001b[39m.\u001b[32mhttp\u001b[39m.\u001b[32mscaladsl\u001b[39m.\u001b[32mserver\u001b[39m.\u001b[32mRequestContext\u001b[39m => \u001b[32mconcurrent\u001b[39m.\u001b[32mFuture\u001b[39m[\u001b[32makka\u001b[39m.\u001b[32mhttp\u001b[39m.\u001b[32mscaladsl\u001b[39m.\u001b[32mserver\u001b[39m.\u001b[32mRouteResult\u001b[39m] = akka.http.scaladsl.server.directives.BasicDirectives$$Lambda$4227/414237822@7cd1986b"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit val system = ActorSystem(\"main-system\")\n",
    "implicit val materializer = ActorMaterializer()\n",
    "implicit val executionContext = system.dispatcher\n",
    "\n",
    "import de.heikoseeberger.akkahttpcirce.FailFastCirceSupport._\n",
    "\n",
    "val route =\n",
    "  path(\"detect\") {\n",
    "      post {\n",
    "          fileUpload(\"img\") {\n",
    "              case (metadata, byteSource) =>\n",
    "              val file = File.createTempFile(\"image\", \".png\")\n",
    "              val fileSaveFut = byteSource.runWith(FileIO.toPath(Paths.get(file.getAbsolutePath)))\n",
    "              onComplete(fileSaveFut) {\n",
    "                  case Success(s) => \n",
    "                      val detections = labelize( detectObjects(file))\n",
    "                      complete(detections)\n",
    "                  case Failure(s) => complete(s.getMessage)\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mbindingFuture\u001b[39m: \u001b[32mconcurrent\u001b[39m.\u001b[32mFuture\u001b[39m[\u001b[32mServerBinding\u001b[39m] = \u001b[32m\u001b[33mSuccess\u001b[39m(\u001b[33mServerBinding\u001b[39m(/127.0.0.1:8080))\u001b[39m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val bindingFuture = Http().bindAndHandle(route, \"localhost\", 8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bindingFuture\n",
    "      .flatMap(_.unbind()) // trigger unbinding from the port\n",
    "      .onComplete(_ => system.terminate()) // and shutdown when done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
