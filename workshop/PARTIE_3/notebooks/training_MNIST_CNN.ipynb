{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2 : MNIST with Convolutional Neural Network (CNN)</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">(Almond 0.8.1, Scala 2.12.8)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Surprise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.Paths\n",
    "\n",
    "import org.platanios.tensorflow.api._\n",
    "\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.Indexer._\n",
    "import org.platanios.tensorflow.api.core.client.Session\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import org.platanios.tensorflow.api.learn.layers.{ Softmax, AddBias, Sigmoid, Dropout, Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean, Conv2D, MaxPool }\n",
    "import org.platanios.tensorflow.api.learn.{ Model, StopCriteria }\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "\n",
    "import org.platanios.tensorflow.api.ops.NN.SameConvPadding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{\n",
    "def displayNumberMNIST(nb: Int) {\n",
    "    val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "    val images = dataset.trainImages\n",
    "    val imagesToDisplay = images.slice(0 :: nb, ::, ::)\n",
    "    for (index <- 0 until nb) {\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imagesToDisplay(index).reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "displayNumberMNIST(20)\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data iterator for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "\n",
    "val trainImages = dataset.trainImages.toFloat\n",
    "val trainImagesReshape = tf.data.datasetFromTensorSlices(trainImages.reshape(Shape(dataset.trainImages.shape(0), dataset.trainImages.shape(1), dataset.trainImages.shape(2), 1)))\n",
    "\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImagesReshape.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val input = tf.learn.Input(FLOAT32, Shape(-1, 28, 28, 1))\n",
    "val trainInput = Input(INT64, Shape(-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Topology\n",
    "\n",
    "CNN models are build with a succession of specific Layers:\n",
    "\n",
    "- Convolution Layer to score locally a set of 2D patterns on the 2D grid, e.g. \n",
    "\n",
    "    `Conv2D[Float](\"Layer_0/Conv2D\", Shape(3, 3, 1, 32), 1, 1, SameConvPadding)`\n",
    "    \n",
    "    \n",
    "- Rectifying Linear Unit to avoid symetric detections (mirror effects), e.g.\n",
    "\n",
    "    `ReLU[Float](\"Layer_0/ReLU\")`\n",
    "    \n",
    "    \n",
    "- Pooling scores to select the best pattern in a given region, e.g.\n",
    "\n",
    "   `MaxPool[Float](\"Layer_0/MaxPool\", Seq(1, 2, 2, 1), 1, 1, SameConvPadding)`\n",
    "   \n",
    "Successive such layers bring a hierarchy of pattern detection/selection\n",
    "\n",
    "Then ends with a Flatttening from 2D to 1D (remove locality), a fully connected layer and the ouptut layer to assess the classes of different such patterns. \n",
    "\n",
    "\n",
    "TODO:\n",
    "\n",
    "Find a better model, try to reach > 0.96 accuracy, (15-20 mins exercise):\n",
    "\n",
    "- add a Convolution of shape (3, 3, 32, 64)?\n",
    "- add a Convolution of shape (3, 3, 64, 128)?\n",
    "- add some `Dropout(\"Embedding/Dropout\", 0.33F)` after Flatten ?\n",
    "- add some steps ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "// Create the CNN model.\n",
    "val layer = \n",
    "        Conv2D[Float](\"Layer_0/Conv2D\", Shape(3, 3, 1, 32), 1, 1, SameConvPadding) >>\n",
    "        ReLU[Float](\"Layer_0/ReLU\") >>\n",
    "        MaxPool[Float](\"Layer_0/MaxPool\", Seq(1, 2, 2, 1), 1, 1, SameConvPadding) >>\n",
    "        Flatten[Float](\"Layer_2/Flatten\") >>\n",
    "        Linear[Float](\"OutputLayer/Linear\", 128) >>\n",
    "        Linear[Float](\"OutputLayer/Linear\", 10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, Optimizer and wrapping in an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.Adam()\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)\n",
    "\n",
    "// Create an estimator and train the model.\n",
    "val estimator = InMemoryEstimator(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val start = System.currentTimeMillis()\n",
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(12)))\n",
    "val end = System.currentTimeMillis()\n",
    "println(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.reshape(Shape(images.shape(0), images.shape(1), images.shape(2), 1)).toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "val nbSample = 1000\n",
    "println(s\"Train accuracy = ${accuracy(dataset.trainImages.slice(0 :: nbSample, ::, ::), dataset.trainLabels.slice(0 :: nbSample))}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataset.testImages.slice(0 :: nbSample, ::, ::), dataset.testLabels.slice(0 :: nbSample))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val images = dataset.testImages\n",
    "\n",
    "def inferOnSelectedImage(indexes: Seq[Int], images: Tensor[UByte]) {\n",
    "    indexes.foreach { index => \n",
    "        val imageToInfer = images.slice(index, ::, ::).reshape(Shape(1, 28, 28, 1))\n",
    "        val predictions = estimator.infer(() => imageToInfer.toFloat)\n",
    "        println(s\"Label infered: ${predictions.argmax(1).scalar}\")\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imageToInfer.reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "\n",
    "inferOnSelectedImage((10 to 20), images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
