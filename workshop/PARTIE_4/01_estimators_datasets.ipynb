{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow High Level APIs introduction\n",
    "\n",
    "This notebook introduces the scala_tensorflow library high-level APIs (Dataset and Estimators) for a simple regression model case.\n",
    "\n",
    "Summary:\n",
    "\n",
    "- load data into a Tensor, make a Dataset\n",
    "- Create a model Estimator\n",
    "- Train\n",
    "- Tensorflow training vizualization\n",
    "- Save Model\n",
    "- Model Signature\n",
    "- Infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys.process._\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.learn._\n",
    "import org.platanios.tensorflow.api.learn.layers._\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.core.client.FeedMap\n",
    "\n",
    "import java.nio.file.Paths\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val rootDir = \"resources/\"  //sys.env(\"HOME\") + \"/data/immo/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s\"head -3 ${rootDir}immo.csv\"!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val bufferedSource = scala.io.Source.fromFile(s\"${rootDir}immo.csv\")\n",
    "lazy val tt = bufferedSource.getLines.drop(1).toVector\n",
    "                       .map(_.split(\",\").map(_.trim.toFloat))\n",
    "                       .map(arr => Tensor(arr(0), arr(1), arr(2), arr(3), arr(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sess = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataTensor = Tensor(tt:_*)\n",
    "\n",
    "val meanD = tf.mean(dataTensor, axes = Seq(0), keepDims = true, name = \"Mean\")\n",
    "val varianceD = tf.mean( tf.squaredDifference(meanD, tf.stopGradient(dataTensor)), axes = Seq(0), keepDims = true, name = \"Variance\")\n",
    "\n",
    "val dataScaled = tf.divide(tf.subtract(dataTensor, meanD), tf.sqrt(varianceD))\n",
    "val dataScaledTensor = sess.run(fetches = dataScaled)\n",
    "\n",
    "val trainFeatures = tf.data.datasetFromTensorSlices(dataScaledTensor(---, 1::))\n",
    "val trainLabels   = tf.data.datasetFromTensorSlices(dataScaledTensor(---, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trainData =\n",
    "  trainFeatures.zip(trainLabels)\n",
    "      .repeat()\n",
    "      //.shuffle(10)\n",
    "      .batch(250)\n",
    "      .prefetch(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val input = Input(FLOAT32, Shape(-1, 4))\n",
    "val trainInput = Input(FLOAT32, Shape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.platanios.tensorflow.api.ops.variables._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val layers =  Linear[Float](\"Layer_0\", 1)\n",
    "val loss = L2Loss[Float, Float](\"Loss\") >> ScalarSummary(name = \"Loss\", tag = \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val optimizer = tf.train.AdaGrad(1.0f)//tf.train.GradientDescent(1e-6f)\n",
    "val model = Model.simpleSupervised(input, trainInput, layers, loss, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.platanios.tensorflow.api.learn.hooks._\n",
    "import org.platanios.tensorflow.api.config.TensorBoardConfig\n",
    "\n",
    "\n",
    "val summariesDir = java.nio.file.Paths.get(\"/tmp/001tfsc\")\n",
    "\n",
    "val estimator = InMemoryEstimator(\n",
    "  modelFunction = model,\n",
    "  configurationBase = Configuration(Some(summariesDir)),\n",
    "  trainHooks = Set(\n",
    "    SummarySaver(summariesDir, StepHookTrigger(10)),\n",
    "    tf.learn.StepRateLogger(log = true, summaryDir = summariesDir, trigger = tf.learn.StepHookTrigger(100)),\n",
    "    tf.learn.LossLogger(trigger = tf.learn.StepHookTrigger(10)),\n",
    "    CheckpointSaver(summariesDir, StepHookTrigger(10))),\n",
    "  tensorBoardConfig = TensorBoardConfig(summariesDir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val scaledPreds = estimator.infer(() => dataScaledTensor(---, 1::))\n",
    "val predsOp = tf.add(meanD(---,0),tf.multiply(scaledPreds,tf.sqrt(varianceD(---,0))))\n",
    "//val preds = tf.sum(meanD(---,0), tf.multiply(scaledPreds, tf.sqrt(varianceD(---,0))))\n",
    "val (preds, m, sd2) = sess.run(fetches = (predsOp,meanD,varianceD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledPreds(---, 0).entriesIterator.toSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2(---,0).entriesIterator.toSeq//.map(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataScaledTensor(---, 0).entriesIterator.toSeq.map(x =>x*x).reduce(_+_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
