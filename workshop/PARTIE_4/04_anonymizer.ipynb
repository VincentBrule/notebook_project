{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Anonymization with Tensorflow Scala</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Only for RVB image, small changes are necessary if you need to use it for grascales image*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\"com.github.haifengl\" % \"smile-scala_2.12\" % \"1.5.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(\"org.platanios\", \"tensorflow_2.12\"),\n",
    "    version = \"0.4.1\",\n",
    "    // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "    attributes = coursier.Attributes(\"\", \"darwin-cpu-x86_64\")\n",
    "  )\n",
    ")\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interp.load.ivy(\n",
    "  coursier.Dependency(\n",
    "    module = coursier.Module(coursier.Organization(\"org.platanios\"), coursier.ModuleName(\"tensorflow_2.12\")),\n",
    "    version = \"0.4.1\",\n",
    "    // replace with linux-gpu-x86_64 on linux with nvidia gpu or with darwin-cpu-x86_64 on macOS \n",
    "    attributes = coursier.Attributes(coursier.Type(\"\"), coursier.Classifier(\"darwin-cpu-x86_64\"))\n",
    "  )\n",
    ")\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.tensorflow.framework.GraphDef\n",
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.ops.{Files, Image => TImage}\n",
    "import org.platanios.tensorflow.api.core.types.UByte\n",
    "import org.platanios.tensorflow.api.core.client.FeedMap\n",
    "import java.io.{BufferedInputStream, File, FileInputStream}\n",
    "import scala.math.sqrt\n",
    "import scala.math.abs\n",
    "import smile.stat.distribution.GaussianDistribution\n",
    "import org.platanios.tensorflow.api.ops.NN._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "*Modify path to directories in function of your configuration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val basedir = \"data/models\"\n",
    "val modelname = \"anonymizer\"\n",
    "val modelfilename = \"weights_face_v1.0.0.pb\"\n",
    "val modelGraphPath = sys.env.getOrElse(\"HOME\", \"/tmp\") + s\"/${basedir}/${modelname}/${modelfilename}\"\n",
    "\n",
    "val imageFilePath = sys.env(\"HOME\") + \"/Downloads/baywatch.png\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "val basedir = \"data/models\"\n",
    "val modelname = \"anonymizer\"\n",
    "val modelfilename = \"weights_face_v1.0.0.pb\"\n",
    "val imageFilePath = sys.env(\"HOME\") + \"/Desktop/audiScala/xavier/coco01.png\"\n",
    "val modelGraphPath = sys.env.getOrElse(\"HOME\", \"/tmp\") + s\"/Desktop/audiScala/xavier/${modelfilename}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy val graphDef = GraphDef.parseFrom(\n",
    "    new BufferedInputStream(new FileInputStream(new File(modelGraphPath))))\n",
    "lazy val graph = Graph.fromGraphDef(graphDef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val session = Session(graph)\n",
    "val sessionSimple = Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare recuperation of graph results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imagePlaceholder = graph.getOutputByName(\"image_tensor:0\").toUByte\n",
    "val detectionBoxes = graph.getOutputByName(\"detection_boxes:0\").toFloat\n",
    "val detectionScores = graph.getOutputByName(\"detection_scores:0\").toFloat\n",
    "val detectionClasses = graph.getOutputByName(\"detection_classes:0\").toFloat\n",
    "val numDetections = graph.getOutputByName(\"num_detections:0\").toFloat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and transform image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (imgTensor, fileNamePlaceholder) = tf.createWith(graph = graph) {\n",
    "    val fileNamePlaceholder = tf.placeholder[String]()\n",
    "    val fileTensor = Files.readFile(fileNamePlaceholder)\n",
    "    val imgTensor = TImage.decodePng(fileTensor, 3)\n",
    "    (imgTensor, fileNamePlaceholder)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val file = new File(imageFilePath)\n",
    "val fileNameTensor = Tensor.fill(Shape())(file.getAbsolutePath())\n",
    "val feedImg = FeedMap(Map(fileNamePlaceholder -> fileNameTensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imageOuts: Tensor[UByte] = session.run(fetches = imgTensor, feeds = feedImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val feeds = FeedMap(Map(imagePlaceholder -> imageOuts.slice(NewAxis, ---)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection of face \n",
    "*boxes* = Positions of face detected\n",
    "\n",
    "*score* = Confidence for each detection\n",
    "\n",
    "*classes* = Face or plate\n",
    "\n",
    "*num* = Number of detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val Seq(boxes, scores, classes, num) =\n",
    "      session.run(\n",
    "        fetches =\n",
    "          Seq(detectionBoxes, detectionScores, detectionClasses, numDetections),\n",
    "        feeds = feeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val width = imageOuts.shape(1)\n",
    "val height = imageOuts.shape(0)\n",
    "val thereshold = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter detections to keep only one above our thereshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tabBoxes = for {\n",
    "    i <- 0 until num(0).scalar.asInstanceOf[Float].toInt\n",
    "    labelId = classes(0, i).toFloat.scalar.toInt\n",
    "    box = boxes(0, i).toFloat.entriesIterator.toSeq\n",
    "    y1 = (box(0) * height).toInt\n",
    "    x1 = (box(1) * width).toInt\n",
    "    y2 = (box(2) * height).toInt\n",
    "    x2 = (box(3) * width).toInt\n",
    "    labelBox = (y1, x1, y2, x2)\n",
    "    score = scores(0, i).toFloat.scalar\n",
    "  } yield (labelId, score, labelBox)\n",
    "\n",
    "val tabBoxesFiltered = tabBoxes.filter {case (_,y,_) => y > thereshold}\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a mask to delimitate areas where the blurring need to be apply in the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 0 is corresponding to an area where no blur is necessary and 1 is the opposite\n",
    "val maskBlur = Array.fill(height, width)(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// Thanks to the box detection, we fill our mask with 1 where we need to apply blurring\n",
    "tabBoxesFiltered.map {case (x,y,z) => z}\n",
    "                .foreach {case (x1,y1,x2,y2) => (x1 until x2)\n",
    "                    .foreach(xi => (y1 until y2)\n",
    "                        .foreach(yi => maskBlur(xi)(yi) = 1))\n",
    "}\n",
    "val maskBlurFlatten = maskBlur.flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tensorMaskFlatten = Tensor(maskBlurFlatten)\n",
    "val tensorMaskReshape = tf.reshape(tensorMaskFlatten, Shape(height, width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params for blurring and smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val channels = 3 // RVB = 3\n",
    "val smooth_boxes = true // Smooth area around blurring\n",
    "val kernel_size = 21 // Kernel for blurring\n",
    "val sigma = 2 // Standard deviation for blurring\n",
    "val box_kernel_size = 9 // Size for smoothing, need to be > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a 2D gaussian filter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val gaussian = new GaussianDistribution(0.0, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val interval = (2 * sigma + 1.0) / kernel_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val g1dcdf = (-sigma - interval/2.0 to sigma + interval/2.0 by (2.0*sigma + interval)/kernel_size)\n",
    "    .map(gaussian.cdf(_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val k1d = g1dcdf.sliding(2).map { case Seq(x, y) => y - x }.toArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val k1dSqrt = for {\n",
    "    x <- k1d\n",
    "    y <- k1d\n",
    "} yield sqrt(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sumK1d = k1dSqrt.sum\n",
    "val kernel = k1dSqrt.map(x => x/sumK1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val kernelBlurring = tf.reshape(kernel, Shape(kernel_size, kernel_size, 1, 1)).toFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate smoothing filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filter_size = List(box_kernel_size, box_kernel_size)\n",
    "val factor: List[Int] = filter_size.map(size => ((size + 1) / 2).toInt)\n",
    "val centerX = if (filter_size(0) % 2 == 1) factor(0) - 1 else factor(0) - 0.5\n",
    "val centerY = if (filter_size(1) % 2 == 1) factor(1) - 1 else factor(1) - 0.5\n",
    "\n",
    "val vectorX = (0 until filter_size(0)).toList\n",
    "val vectorY = (0 until filter_size(1)).toList\n",
    "val kernelTemp = Array.ofDim[Float](filter_size(0), filter_size(1))\n",
    "\n",
    "(0 until filter_size(0))\n",
    "    .foreach(i => (0 until filter_size(1))\n",
    "        .foreach(j => {\n",
    "            kernelTemp(i)(j) = (1.0f - abs(vectorX(i) - centerX).toFloat / factor(0).toFloat) * (1.0f - abs(vectorY(j) - centerY).toFloat / factor(1).toFloat)\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "val kernelFlat = kernelTemp.flatten\n",
    "val sumSmoothing = kernelFlat.sum\n",
    "val kernelSmoothing = Tensor(kernelFlat.map(element => element / sumSmoothing))\n",
    "val tensorSmoothing = tf.reshape(kernelSmoothing, Shape(filter_size(0), filter_size(1), 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply blurring with our gaussian kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding before the convolution to avoid border effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pad = (kernel_size - 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val paddings = Tensor(Tensor(pad, pad), Tensor(pad, pad), Tensor(0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imageWithPadding = (tf.pad(imageOuts, paddings=paddings, mode=tf.ReflectivePadding)).toFloat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutions on each channel\n",
    "\n",
    "We need to do a little trick because the original python code use the function *tf.nn.depthwise_conv2d_native*. \n",
    "\n",
    "Unfortunately, this function doesn't exist inside Tensorflow **Scala**.\n",
    "\n",
    "To replace this function, we split the image between each channel (Red, green and blue).\n",
    "\n",
    "After that, we use the basic convolution on each channel with our gaussian kernel.\n",
    "\n",
    "Finally, we re-combined all channel to have the blurred image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tabImages = (0 to 2).toList.map(i => tf.slice(imageWithPadding, Tensor(0,0,i), Tensor(-1,-1,1)).toFloat)\n",
    "val tabImages4D = tabImages.map(img => img.slice(NewAxis, ---))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tensorMaskReshapeFinal = (tensorMaskReshape.slice(NewAxis, ---, NewAxis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution to combined gaussian filter and original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tabConvolution = tabImages4D.map(colors => tf.conv2D(input = colors, filter = kernelBlurring, stride1 = 1, stride2 = 1, padding=org.platanios.tensorflow.api.ops.NN.ValidConvPadding))\n",
    "val imageAfterConvolution = tf.concatenate(inputs = tabConvolution, axis = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution to smooth the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val smoothedMask = tf.reshape(tf.conv2D(input = tensorMaskReshapeFinal.toFloat, filter = tensorSmoothing, stride1 = 1, stride2 = 1, padding=org.platanios.tensorflow.api.ops.NN.SameConvPadding, name=\"smooth_mask\"), Shape(height, width, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined blurred image and mask to only blur necessary areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val reshapeBlur = tf.reshape(imageAfterConvolution, Shape(height, width, channels))\n",
    "val imageWithoutBox = imageOuts.toFloat * (Tensor(1.0f) - smoothedMask)\n",
    "val imageCombined = ((reshapeBlur * smoothedMask) + imageWithoutBox).toUByte\n",
    "\n",
    "val bluredImage = sessionSimple.run(fetches = imageCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imgFinal = tf.createWith(graph = graph) {\n",
    "    val exampleImage = tf.decodeRaw[Byte](tf.image.encodePng(bluredImage))\n",
    "    session.run(fetches = exampleImage)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromArray(imgFinal.entriesIterator.toArray, Image.PNG, width=Some(\"500\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
