{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"text-align: center;, font-style: strong;\">Partie 2 : MNIST with Multiple Layer Perceptron (MLP)</p>\n",
    "\n",
    "### <p style=\"text-align: center;\">(Almond 0.9.1, Scala 2.12.10)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Usual suspects in Scala TF setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.nio.file.Paths\n",
    "\n",
    "import org.platanios.tensorflow.api._\n",
    "\n",
    "import org.platanios.tensorflow.api.tf\n",
    "import org.platanios.tensorflow.api.tensors.Tensor\n",
    "import org.platanios.tensorflow.api.core.Shape\n",
    "import org.platanios.tensorflow.api.core.Indexer._\n",
    "import org.platanios.tensorflow.api.core.client.Session\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "\n",
    "import org.platanios.tensorflow.api.learn.layers.{ Flatten, Input, Linear, ReLU, SparseSoftmaxCrossEntropy, Mean }\n",
    "import org.platanios.tensorflow.api.learn.{ Model, StopCriteria }\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display MNIST Dataset\n",
    "\n",
    "Define and execute a function to display the first 20 images found in the written digits images database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{{\n",
    "def displayNumberMNIST(nb: Int) {\n",
    "    val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "    val images = dataset.trainImages\n",
    "    val imagesToDisplay = images.slice(0 :: nb, ::, ::)\n",
    "    for (index <- 0 until nb) {\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imagesToDisplay(index).reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "displayNumberMNIST(20)\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splits\n",
    "\n",
    "We need to define a iterator on data, looping and shuffling. Loading in batches of 256 images at a time.\n",
    "\n",
    "Each training iteratiuon will use 256 images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val dataset = MNISTLoader.load(Paths.get(\"../resources/dataset\"))\n",
    "val trainImages = tf.data.datasetFromTensorSlices(dataset.trainImages.toFloat)\n",
    "\n",
    "val trainLabels = tf.data.datasetFromTensorSlices(dataset.trainLabels.toLong)\n",
    "val trainData =\n",
    "  trainImages.zip(trainLabels)\n",
    "      .repeat()\n",
    "      .shuffle(10000)\n",
    "      .batch(256)\n",
    "      .prefetch(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition\n",
    "\n",
    "We define here the shape for input data and the Neural Network topology.\n",
    "\n",
    "We start by reshaping the 28x28 matrix as a flat vector\n",
    "\n",
    "Then we connect these cells to a single 256 nodes layer, fully connected\n",
    "\n",
    "Then again connect these to a 10-cells output (because we have 10 classes = 10 digits)\n",
    "\n",
    "# TODO:\n",
    "\n",
    "- Add a second fully connected Layer\n",
    "- test the use of a Rectifying Linear Unit at each layer output like `ReLU[Float](\"Layer_0/Activation\")`\n",
    "- test more steps..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create the MLP model.\n",
    "val input = Input(FLOAT32, Shape(-1, 28, 28))\n",
    "val trainInput = Input(INT64, Shape(-1))\n",
    "val layer = Flatten[Float](\"Input/Flatten\") >> \n",
    "    Linear[Float](\"Layer_0\", 256)  >>\n",
    "    Linear[Float](\"OutputLayer\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss, optimization and wrapping in an Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val loss = SparseSoftmaxCrossEntropy[Float, Long, Float](\"Loss\") >>\n",
    "    Mean(\"Loss/Mean\")\n",
    "val optimizer = tf.train.Adam()\n",
    "val model = Model.simpleSupervised(input, trainInput, layer, loss, optimizer)\n",
    "\n",
    "// Create an estimator and train the model.\n",
    "val estimator = InMemoryEstimator(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.train(() => trainData, StopCriteria(maxSteps = Some(2500)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for model quality: accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(images: Tensor[UByte], labels: Tensor[UByte]): Float = {\n",
    "    val predictions = estimator.infer(() => images.toFloat)\n",
    "    predictions\n",
    "      .argmax(1).toUByte\n",
    "      .equal(labels).toFloat\n",
    "      .mean().scalar\n",
    "}\n",
    "\n",
    "println(s\"Train accuracy = ${accuracy(dataset.trainImages, dataset.trainLabels)}\")\n",
    "println(s\"Test accuracy = ${accuracy(dataset.testImages, dataset.testLabels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val images = dataset.testImages\n",
    "\n",
    "def inferOnSelectedImage(indexes: Seq[Int], images: Tensor[UByte]) {\n",
    "    indexes.foreach { index => \n",
    "        val imageToInfer = images.slice(index, ::, ::).reshape(Shape(1, 28, 28))\n",
    "        val predictions = estimator.infer(() => imageToInfer.toFloat)\n",
    "        println(s\"Label infered: ${predictions.argmax(1).scalar}\")\n",
    "        val png = Session().run(fetches = tf.decodeRaw[Byte](tf.image.encodePng(imageToInfer.reshape(Shape(28, 28, 1)))))\n",
    "        Image(png.entriesIterator.toArray).withFormat(Image.PNG).withWidth(100).withHeight(100).display \n",
    "    }\n",
    "}\n",
    "\n",
    "inferOnSelectedImage((30 to 40), images)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
