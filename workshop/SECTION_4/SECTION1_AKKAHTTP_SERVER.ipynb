{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "\n",
    "## Object Detection through HTTP Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scala TF dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.load.ivy(coursierapi.Dependency.of(\"org.platanios\", \"tensorflow_2.12\", \"0.4.1\").withClassifier(\"linux-cpu-x86_64\"))\n",
    "interp.load.ivy(\"org.platanios\" %% \"tensorflow-data\" % \"0.4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.platanios.tensorflow.api._\n",
    "import org.platanios.tensorflow.api.learn._\n",
    "import org.platanios.tensorflow.api.learn.layers._\n",
    "import org.platanios.tensorflow.api.learn.estimators.InMemoryEstimator\n",
    "import org.platanios.tensorflow.data.image.MNISTLoader\n",
    "import org.platanios.tensorflow.api.core.client.FeedMap\n",
    "import org.tensorflow.framework.GraphDef\n",
    "\n",
    "import org.platanios.tensorflow.api.ops.Files\n",
    "import org.platanios.tensorflow.api.ops.Image\n",
    "import scala.io.Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import java.net.URL\n",
    "import sys.process._\n",
    "import java.io.{BufferedInputStream, File, FileInputStream}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the model to be served\n",
    "\n",
    "### We download the published Tensorflow model from a public URL\n",
    "\n",
    "See https://github.com/tensorflow/models for reference on available models from research community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cacheDir = \"resources\"//sys.env(\"HOME\") + \"/data/models/tmp\"\n",
    "// val modelName = \"ssd_mobilenet_v2_coco_2018_03_29\"\n",
    "val modelName = \"mask_rcnn_resnet50_atrous_coco_2018_01_28\"\n",
    "val archiveFilename = s\"${modelName}.tar.gz\"\n",
    "\n",
    "// val modelURL = s\"http://download.tensorflow.org/models/object_detection/${archiveFilename}\"\n",
    "val modelURL = s\"http://download.tensorflow.org/models/object_detection/$archiveFilename\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// THIS CELL WAS CHANGED TO MARKDOW TO AVOID EXECUTING A HEAVY DOWNLOAD THAT WAS ALREADY DONE\n",
    "\n",
    "new URL(modelURL) #> new File(s\"${cacheDir}/${archiveFilename}\") !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction of the model archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// THIS CELL WAS CHANGED TO MARKDOW TO AVOID EXECUTING AN UNARCHIVE THAT WAS ALREADY DONE\n",
    "s\"tar -xzf ${cacheDir}/${archiveFilename} -C ${cacheDir}\" !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s\"ls ${cacheDir}/${modelName}\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model in a Tensorflow Session\n",
    "\n",
    "In the extracted directory, named after the `modelName`, we are interested in loading the `frozen_inference_graph.pb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val modelGraphPath = s\"${cacheDir}/${modelName}_2018_01_28/frozen_inference_graph.pb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lazy val graphDef = GraphDef.parseFrom(\n",
    "    new BufferedInputStream(new FileInputStream(new File(modelGraphPath))))\n",
    "val graph = Graph.fromGraphDef(graphDef)\n",
    "val session = Session(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add nodes to access the model signature (input and responses)\n",
    "\n",
    "`image_tensor` is the tensor representing the input images, with 3-channels colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val imagePlaceholder = graph.getOutputByName(\"image_tensor:0\").toUByte\n",
    "imagePlaceholder.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`num_detections` is the number of detected objects\n",
    "\n",
    "`detection_boxes` are the corrdinates of detected objects\n",
    "\n",
    "`detection_scores` are a probability-like score for each object\n",
    "\n",
    "`detection_classes` are the class label for each detection\n",
    "\n",
    "**TODO: Complete the definition of Outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val detectionBoxes = graph.getOutputByName(\"detection_boxes:0\")\n",
    "val detectionScores = graph.getOutputByName(\"detection_scores:0\")\n",
    "val detectionClasses = graph.getOutputByName(\"detection_classes:0\")\n",
    "val numDetections = graph.getOutputByName(\"num_detections:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nodes to feed the graph with an image file path\n",
    "\n",
    "A Placeholder to provide a filepathe is the input, and the file is opened and decoded as an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val (imgTensor, fileNamePlaceholder) = tf.createWith(graph = graph) {\n",
    "    val fileNamePlaceholder = tf.placeholder[String]()\n",
    "    val fileTensor = Files.readFile(fileNamePlaceholder)\n",
    "    val imgTensor = Image.decodePng(fileTensor, 3)\n",
    "    (imgTensor, fileNamePlaceholder)\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Service function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectObjects(file: File) = {\n",
    "    \n",
    "    // Feed the image file to get the Images Tensor\n",
    "    val fileNameTensor = Tensor.fill(Shape())(file.getAbsolutePath())\n",
    "    val feedImg = FeedMap(fileNamePlaceholder, fileNameTensor)\n",
    "    val imageOuts: Tensor[UByte] =\n",
    "      session.run(fetches = imgTensor, feeds = feedImg)\n",
    "\n",
    "    // Retain image sizes to format output later\n",
    "    val width = imageOuts.shape(1)\n",
    "    val height = imageOuts.shape(0)\n",
    "\n",
    "    // Feed with Images to compute detections:\n",
    "    val feeds = FeedMap(imagePlaceholder, imageOuts.slice(NewAxis, ---))\n",
    "    val Seq(boxes, scores, classes, num) =\n",
    "      session.run(\n",
    "        fetches =\n",
    "          Seq(detectionBoxes, detectionScores, detectionClasses, numDetections),\n",
    "        feeds = feeds)\n",
    "    \n",
    "  val labelList =\n",
    "      for {\n",
    "        i <- 0 until num(0).scalar.asInstanceOf[Float].toInt\n",
    "        labelId = classes(0, i).toFloat.scalar.toInt\n",
    "        //label = labelMap.getOrElse(labelId, \"unknown\")\n",
    "        //if setOfClasses.isEmpty || setOfClasses.contains(label)\n",
    "\n",
    "        box = boxes(0, i).toFloat.entriesIterator.toSeq\n",
    "        x1 = (box(1) * width).toInt\n",
    "        y1 = (box(0) * height).toInt\n",
    "        x2 = (box(3) * width).toInt\n",
    "        y2 = (box(2) * height).toInt\n",
    "        labelBox = (x1, y1, x2 - x1 + 1, y2 - y1 + 1)\n",
    "        score = scores(0, i).toFloat.scalar\n",
    "      } yield (labelId, score, x1, y1, x2, y2)\n",
    "    labelList.toSeq\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectObjects(new File(\"resources/baywatch.jpg\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform Labels IDs in labels\n",
    "\n",
    "Link number label to its text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val labelsMapPath = \"resources/coco_labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val labelsMapToString = Source.fromFile(labelsMapPath).getLines.map { line =>\n",
    "        val splitLine = line.split(\" \")\n",
    "        splitLine(0).toInt -> splitLine(1)\n",
    "    }.toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`io.circe:circe-core_2.12:0.10.1`\n",
    "import $ivy.`io.circe:circe-generic_2.12:0.10.1`\n",
    "import $ivy.`io.circe:circe-parser_2.12:0.10.1`\n",
    "import _root_.io.circe.{Decoder, Encoder}\n",
    "\n",
    "case class Detection(label: String, score: Float, x1: Int, y1: Int, x2: Int, y2: Int)\n",
    "\n",
    "object Detection {\n",
    "  import _root_.io.circe.generic.semiauto._\n",
    "\n",
    "  implicit lazy val encoder: Encoder[Detection] = deriveEncoder[Detection]\n",
    "  implicit lazy val decoder: Decoder[Detection] = deriveDecoder[Detection]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelize(detections: Seq[(Int, Float, Int, Int, Int, Int)]) = detections.map { \n",
    "    d => d match {\n",
    "        case (id, score, x1, y1, x2, y2) if (labelsMapToString.contains(id)) => Detection(labelsMapToString(id), score, x1, y1, x2, y2)\n",
    "        case (id, score, x1, y1, x2, y2) => Detection(\"unknown\", score, x1, y1, x2, y2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelize(detectObjects(new File(\"resources/baywatch.jpg\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run an akka-http service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`com.typesafe.akka:akka-http_2.12:10.1.5`\n",
    "import $ivy.`com.typesafe.akka:akka-actor_2.12:2.5.18`\n",
    "import $ivy.`com.typesafe.akka:akka-stream_2.12:2.5.18`\n",
    "import $ivy.`de.heikoseeberger:akka-http-circe_2.12:1.21.0`\n",
    "\n",
    "import akka.actor.ActorSystem\n",
    "import akka.stream.{IOResult, Materializer}\n",
    "import akka.stream.scaladsl.{FileIO, Source}\n",
    "import akka.http.scaladsl.Http\n",
    "import akka.http.scaladsl.Http.ServerBinding\n",
    "import akka.http.scaladsl.server.Directives._\n",
    "import akka.http.scaladsl.server.Route\n",
    "import akka.stream.ActorMaterializer\n",
    "import akka.util.ByteString\n",
    "\n",
    "import scala.util.{Failure, Success}\n",
    "import java.nio.file.{Files, Paths}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit val system = ActorSystem(\"main-system\")\n",
    "implicit val materializer = ActorMaterializer()\n",
    "implicit val executionContext = system.dispatcher\n",
    "\n",
    "import de.heikoseeberger.akkahttpcirce.FailFastCirceSupport._\n",
    "\n",
    "val route =\n",
    "  path(\"detect\") {\n",
    "      post {\n",
    "          withoutRequestTimeout {\n",
    "              fileUpload(\"img\") {\n",
    "                  case (metadata, byteSource) =>\n",
    "                  val file = File.createTempFile(\"image\", \".png\")\n",
    "                  val fileSaveFut = byteSource.runWith(FileIO.toPath(Paths.get(file.getAbsolutePath)))\n",
    "                  onComplete(fileSaveFut) {\n",
    "                      case Success(s) => \n",
    "                          val detections = labelize( detectObjects(file))\n",
    "                          complete(detections)\n",
    "                      case Failure(s) => complete(s.getMessage)\n",
    "                  }\n",
    "              }\n",
    "          }\n",
    "      }\n",
    "  }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val bindingFuture = Http().bindAndHandle(route, \"localhost\", 8080)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// DO NOT EXECUTE UNTIL YOU WANT TO KILL THE SERVER!\n",
    "\n",
    "bindingFuture\n",
    "      .flatMap(_.unbind()) // trigger unbinding from the port\n",
    "      .onComplete(_ => system.terminate()) // and shutdown when done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
